{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "64OJ5uNRVIy5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import copy\n",
        "\n",
        "import torchmetrics\n",
        "\n",
        "from conplex_dti.model.architectures import SimpleCoembeddingNoSigmoid\n",
        "\n",
        "from conplex_dti.dataset.datamodules import DTIDataModule\n",
        "from conplex_dti.featurizer import get_featurizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u0RmY82aZwyn"
      },
      "outputs": [],
      "source": [
        "# Necessary for TransferCoembedding class\n",
        "# TODO: eventually move TransferCoembedding class to architectures.py\n",
        "class Cosine(nn.Module):\n",
        "    def forward(self, x1, x2):\n",
        "        return nn.CosineSimilarity()(x1, x2)\n",
        "\n",
        "DISTANCE_METRICS = {\"Cosine\": Cosine}\n",
        "ACTIVATIONS = {\"ReLU\": nn.ReLU }\n",
        "\n",
        "\n",
        "# Create a new model that has 2 layers of tensors instead of 1.\n",
        "class TransferCoembedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pre_trained_model:SimpleCoembeddingNoSigmoid,\n",
        "        drug_shape=2048,\n",
        "        target_shape=1024,\n",
        "        latent_dimension=1024,\n",
        "        latent_activation=\"ReLU\",\n",
        "        latent_distance=\"Cosine\",\n",
        "        classify=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # TODO: initialize these all baased on the pre-trained model\n",
        "        self.drug_shape = drug_shape\n",
        "        self.target_shape = target_shape\n",
        "        self.latent_dimension = latent_dimension\n",
        "        self.do_classify = classify\n",
        "        self.latent_activation = ACTIVATIONS[latent_activation]\n",
        "\n",
        "        self.drug_projector = nn.Sequential(\n",
        "            nn.Linear(self.drug_shape, latent_dimension),     # [0]\n",
        "            self.latent_activation(),                         # [1]\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),    # [2]\n",
        "            self.latent_activation()                          # [3]\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.drug_projector[0] = copy.deepcopy(pre_trained_model.drug_projector[0])\n",
        "        # initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.drug_projector[2].weight)\n",
        "\n",
        "        self.target_projector = nn.Sequential(\n",
        "            nn.Linear(self.target_shape, latent_dimension),\n",
        "            self.latent_activation(),\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),\n",
        "            self.latent_activation()\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.target_projector[0] = copy.deepcopy(pre_trained_model.target_projector[0])\n",
        "        # initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.target_projector[2].weight)\n",
        "\n",
        "        # freeze the first layers (neural net ) of the target and drug projectors\n",
        "        for idx, param in enumerate(self.parameters()):\n",
        "            if idx == 0 or idx == 1 or idx == 4 or idx == 5:\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "        if self.do_classify: # if True:\n",
        "            self.distance_metric = latent_distance # \"Cosine\"\n",
        "            self.activator = DISTANCE_METRICS[self.distance_metric]() # gives it the Cosine activator function that was written\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        if self.do_classify: # if True:\n",
        "            return self.classify(drug, target)\n",
        "        else:\n",
        "            return self.regress(drug, target)\n",
        "\n",
        "    def classify(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        distance = self.activator(drug_projection, target_projection)\n",
        "        return distance.squeeze()\n",
        "\n",
        "    def regress(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        inner_prod = torch.bmm(\n",
        "            drug_projection.view(-1, 1, self.latent_dimension),\n",
        "            target_projection.view(-1, self.latent_dimension, 1),\n",
        "        ).squeeze()\n",
        "        return inner_prod.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bcthvn10mFQr"
      },
      "outputs": [],
      "source": [
        "# TODO: want to try learning / training on three different models\n",
        "\n",
        "# 1. TransferCoembedding model with two unfrozen layers\n",
        "# 2. original model with only RELU layer unfrozen\n",
        "# 3. original model with lower learning rate\n",
        "\n",
        "\n",
        "# TODO: eventually do do weights and biases logging\n",
        "# TODO: eventually do logg instead of print statements\n",
        "# TODO: eventually add timing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "J9Pg3cj10xUg"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cpu\")\n",
        "BATCH_SIZE = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Drug and target featurizers already exist\n",
            "Morgan: 100%|██████████| 80/80 [00:00<00:00, 3247.40it/s]\n",
            "ProtBert: 100%|██████████| 19/19 [00:10<00:00,  1.82it/s]\n"
          ]
        }
      ],
      "source": [
        "# recreate lines 309 -> ~322 from train.py\n",
        "\n",
        "# load the featurizers \n",
        "drug_featurizer = get_featurizer(\"MorganFeaturizer\")\n",
        "# load from pre-trained prot-bert model\n",
        "target_featurizer = get_featurizer(\"ProtBertFeaturizer\")\n",
        "\n",
        "\n",
        "# load data into a drug-target interaction datamodule (combo of dataset/dataloader)\n",
        "datamodule = DTIDataModule(data_dir = \"./new_data/\", drug_featurizer=drug_featurizer, target_featurizer=target_featurizer, batch_size=BATCH_SIZE)\n",
        "datamodule.prepare_data()\n",
        "datamodule.setup()\n",
        "\n",
        "# from the datamodules, get dataloaders to use for training, testing, and validation\n",
        "training_generator = datamodule.train_dataloader()\n",
        "validation_generator = datamodule.val_dataloader()\n",
        "testing_generator = datamodule.test_dataloader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load previous model from state dict!\n",
        "pre_trained_model = SimpleCoembeddingNoSigmoid(2048, 1024, 1024)  # TODO: drug_featurizer.shape, target_featurizer.shape 2048, 1024, 1024\n",
        "pre_trained_model.load_state_dict(torch.load(\"../pre_trained_model/models/ConPLex_v1_BindingDB.pt\", map_location=\"cpu\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: move from notebook to architectures file \n",
        "# from conplex_dti.model.architectures import TransferCoembedding \n",
        "model = TransferCoembedding(pre_trained_model)\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# optimizer:\n",
        "LEARNING_RATE = 0.0001 # not same as sam, larger\n",
        "RESET_AFTER_EPOCHS = 10 # aka lr_t0 from config file TODO: play with this, currently same as sam\n",
        "\n",
        "opt = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE) # AdamW is Adam with weight decay\n",
        "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(opt, T_0=RESET_AFTER_EPOCHS)\n",
        "\n",
        "\n",
        "\n",
        "# More variables\n",
        "NUM_EPOCHS = 250 # TODO: play with this\n",
        "VALIDATE_AFTER_EPOCHS = 1 # TODO: play with this\n",
        "CLASSIFY = True # 309\n",
        "WATCH_METRIC = \"val/aupr\" # 310\n",
        "\n",
        "\n",
        "SAVE_DIRECTORY = \"./saved_models/\" # TODO: eventually change this\n",
        "RUN_ID = \"test_run\" # TODO: eventually change this\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keep track of best model:\n",
        "max_metric = 0\n",
        "model_max = copy.deepcopy(model) # currently last (2) layers are random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# line 413 -> 423, NOT doing contrastive learning\n",
        "\n",
        "# Using Binary Cross Entropy loss function because we are trying to predict a binary label (binding or no binding):\n",
        "loss_fct = torch.nn.BCELoss() \n",
        "\n",
        "# Keep track of how well the model is doing (on each epoch)\n",
        "val_metrics = {\"val/aupr\": torchmetrics.AveragePrecision, \"val/auroc\": torchmetrics.AUROC}\n",
        "test_metrics = {\"test/aupr\": torchmetrics.AveragePrecision, \"test/auroc\": torchmetrics.AUROC}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTIONS FOR TRAINING:\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def step(model, batch, device=None):\n",
        "    if device is None:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    drug, target, label = batch  # target is (D + N_pool)\n",
        "    pred = model(drug.to(device), target.to(device))\n",
        "    label = Variable(torch.from_numpy(np.array(label)).float()).to(device)\n",
        "    return pred, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FUNCTIONS FOR TESTING:\n",
        "def test(model, data_generator, metrics, device=None, classify=True):\n",
        "    \"\"\"\n",
        "    returns a results dictionary with \n",
        "    \"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "    metric_dict = {}\n",
        "\n",
        "    for k, met_class in metrics.items():\n",
        "        if classify:\n",
        "            met_instance = met_class(task=\"binary\")\n",
        "        else:\n",
        "            met_instance = met_class()\n",
        "        met_instance.to(device)\n",
        "        met_instance.reset()\n",
        "        metric_dict[k] = met_instance\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for i, batch in enumerate(data_generator):\n",
        "        pred, label = step(model, batch, device)\n",
        "        if classify:\n",
        "            label = label.int()\n",
        "        else:\n",
        "            label = label.float()\n",
        "\n",
        "        for _, met_instance in metric_dict.items():\n",
        "            met_instance(pred, label)\n",
        "\n",
        "    results = {}\n",
        "    for k, met_instance in metric_dict.items():\n",
        "        res = met_instance.compute()\n",
        "        results[k] = res\n",
        "\n",
        "    for met_instance in metric_dict.values():\n",
        "        met_instance.to(\"cpu\")\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "val_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning Training\n",
            "Trainign epoch is 1\n",
            "loss was 0.784625. Updating learning rate to 0.000098\n",
            "Validation AUPR 0.491271 > previous max 0.000000\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch00.pt\n",
            "Validation at Epoch 1\n",
            "val/aupr: 0.4912711977958679\n",
            "val/auroc: 0.5016475915908813\n",
            "Trainign epoch is 2\n",
            "loss was 0.769535. Updating learning rate to 0.000090\n",
            "Validation AUPR 0.525022 > previous max 0.491271\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch01.pt\n",
            "Validation at Epoch 2\n",
            "val/aupr: 0.525022029876709\n",
            "val/auroc: 0.5553402304649353\n",
            "Trainign epoch is 3\n",
            "loss was 0.710350. Updating learning rate to 0.000079\n",
            "Validation AUPR 0.547615 > previous max 0.525022\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch02.pt\n",
            "Validation at Epoch 3\n",
            "val/aupr: 0.5476152300834656\n",
            "val/auroc: 0.5793758630752563\n",
            "Trainign epoch is 4\n",
            "loss was 0.612409. Updating learning rate to 0.000065\n",
            "Validation AUPR 0.565670 > previous max 0.547615\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch03.pt\n",
            "Validation at Epoch 4\n",
            "val/aupr: 0.5656698942184448\n",
            "val/auroc: 0.5910061001777649\n",
            "Trainign epoch is 5\n",
            "loss was 0.641819. Updating learning rate to 0.000050\n",
            "Validation AUPR 0.574919 > previous max 0.565670\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch04.pt\n",
            "Validation at Epoch 5\n",
            "val/aupr: 0.5749191641807556\n",
            "val/auroc: 0.6032177209854126\n",
            "Trainign epoch is 6\n",
            "loss was 0.624277. Updating learning rate to 0.000035\n",
            "Validation AUPR 0.583623 > previous max 0.574919\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch05.pt\n",
            "Validation at Epoch 6\n",
            "val/aupr: 0.583622932434082\n",
            "val/auroc: 0.6080635786056519\n",
            "Trainign epoch is 7\n",
            "loss was 0.635020. Updating learning rate to 0.000021\n",
            "Validation AUPR 0.586186 > previous max 0.583623\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch06.pt\n",
            "Validation at Epoch 7\n",
            "val/aupr: 0.5861855149269104\n",
            "val/auroc: 0.6103896498680115\n",
            "Trainign epoch is 8\n",
            "loss was 0.631163. Updating learning rate to 0.000010\n",
            "Validation at Epoch 8\n",
            "val/aupr: 0.5849961638450623\n",
            "val/auroc: 0.6115526556968689\n",
            "Trainign epoch is 9\n",
            "loss was 0.621044. Updating learning rate to 0.000002\n",
            "Validation at Epoch 9\n",
            "val/aupr: 0.585699737071991\n",
            "val/auroc: 0.611940324306488\n",
            "Trainign epoch is 10\n",
            "loss was 0.594014. Updating learning rate to 0.000100\n",
            "Validation at Epoch 10\n",
            "val/aupr: 0.5856398940086365\n",
            "val/auroc: 0.611940324306488\n",
            "Trainign epoch is 11\n",
            "loss was 0.592041. Updating learning rate to 0.000098\n",
            "Validation AUPR 0.593305 > previous max 0.586186\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch10.pt\n",
            "Validation at Epoch 11\n",
            "val/aupr: 0.5933051109313965\n",
            "val/auroc: 0.6206629276275635\n",
            "Trainign epoch is 12\n",
            "loss was 0.643966. Updating learning rate to 0.000090\n",
            "Validation AUPR 0.599778 > previous max 0.593305\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch11.pt\n",
            "Validation at Epoch 12\n",
            "val/aupr: 0.59977787733078\n",
            "val/auroc: 0.623570442199707\n",
            "Trainign epoch is 13\n",
            "loss was 0.588841. Updating learning rate to 0.000079\n",
            "Validation AUPR 0.604869 > previous max 0.599778\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch12.pt\n",
            "Validation at Epoch 13\n",
            "val/aupr: 0.6048685908317566\n",
            "val/auroc: 0.6289979219436646\n",
            "Trainign epoch is 14\n",
            "loss was 0.568320. Updating learning rate to 0.000065\n",
            "Validation AUPR 0.608556 > previous max 0.604869\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch13.pt\n",
            "Validation at Epoch 14\n",
            "val/aupr: 0.6085555553436279\n",
            "val/auroc: 0.6324869394302368\n",
            "Trainign epoch is 15\n",
            "loss was 0.581492. Updating learning rate to 0.000050\n",
            "Validation AUPR 0.614253 > previous max 0.608556\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch14.pt\n",
            "Validation at Epoch 15\n",
            "val/aupr: 0.6142532229423523\n",
            "val/auroc: 0.6357821226119995\n",
            "Trainign epoch is 16\n",
            "loss was 0.565701. Updating learning rate to 0.000035\n",
            "Validation AUPR 0.616356 > previous max 0.614253\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch15.pt\n",
            "Validation at Epoch 16\n",
            "val/aupr: 0.6163557767868042\n",
            "val/auroc: 0.6383019685745239\n",
            "Trainign epoch is 17\n",
            "loss was 0.550553. Updating learning rate to 0.000021\n",
            "Validation AUPR 0.617586 > previous max 0.616356\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch16.pt\n",
            "Validation at Epoch 17\n",
            "val/aupr: 0.6175859570503235\n",
            "val/auroc: 0.6398527026176453\n",
            "Trainign epoch is 18\n",
            "loss was 0.569262. Updating learning rate to 0.000010\n",
            "Validation AUPR 0.619421 > previous max 0.617586\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch17.pt\n",
            "Validation at Epoch 18\n",
            "val/aupr: 0.6194214224815369\n",
            "val/auroc: 0.6408218741416931\n",
            "Trainign epoch is 19\n",
            "loss was 0.487091. Updating learning rate to 0.000002\n",
            "Validation AUPR 0.620382 > previous max 0.619421\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch18.pt\n",
            "Validation at Epoch 19\n",
            "val/aupr: 0.6203815340995789\n",
            "val/auroc: 0.6414033770561218\n",
            "Trainign epoch is 20\n",
            "loss was 0.538875. Updating learning rate to 0.000100\n",
            "Validation at Epoch 20\n",
            "val/aupr: 0.6203815340995789\n",
            "val/auroc: 0.6414033770561218\n",
            "Trainign epoch is 21\n",
            "loss was 0.512308. Updating learning rate to 0.000098\n",
            "Validation AUPR 0.625614 > previous max 0.620382\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch20.pt\n",
            "Validation at Epoch 21\n",
            "val/aupr: 0.6256144642829895\n",
            "val/auroc: 0.6433417797088623\n",
            "Trainign epoch is 22\n",
            "loss was 0.505351. Updating learning rate to 0.000090\n",
            "Validation AUPR 0.632165 > previous max 0.625614\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch21.pt\n",
            "Validation at Epoch 22\n",
            "val/aupr: 0.6321653127670288\n",
            "val/auroc: 0.6472184062004089\n",
            "Trainign epoch is 23\n",
            "loss was 0.504715. Updating learning rate to 0.000079\n",
            "Validation AUPR 0.636468 > previous max 0.632165\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch22.pt\n",
            "Validation at Epoch 23\n",
            "val/aupr: 0.6364681720733643\n",
            "val/auroc: 0.6503198146820068\n",
            "Trainign epoch is 24\n",
            "loss was 0.510141. Updating learning rate to 0.000065\n",
            "Validation AUPR 0.640563 > previous max 0.636468\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch23.pt\n",
            "Validation at Epoch 24\n",
            "val/aupr: 0.6405632495880127\n",
            "val/auroc: 0.6536150574684143\n",
            "Trainign epoch is 25\n",
            "loss was 0.385931. Updating learning rate to 0.000050\n",
            "Validation AUPR 0.642230 > previous max 0.640563\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch24.pt\n",
            "Validation at Epoch 25\n",
            "val/aupr: 0.6422300934791565\n",
            "val/auroc: 0.6557472348213196\n",
            "Trainign epoch is 26\n",
            "loss was 0.439153. Updating learning rate to 0.000035\n",
            "Validation AUPR 0.643175 > previous max 0.642230\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch25.pt\n",
            "Validation at Epoch 26\n",
            "val/aupr: 0.6431748867034912\n",
            "val/auroc: 0.65555340051651\n",
            "Trainign epoch is 27\n",
            "loss was 0.525213. Updating learning rate to 0.000021\n",
            "Validation AUPR 0.643401 > previous max 0.643175\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch26.pt\n",
            "Validation at Epoch 27\n",
            "val/aupr: 0.6434012651443481\n",
            "val/auroc: 0.6561349630355835\n",
            "Trainign epoch is 28\n",
            "loss was 0.452526. Updating learning rate to 0.000010\n",
            "Validation at Epoch 28\n",
            "val/aupr: 0.6431605815887451\n",
            "val/auroc: 0.6567164659500122\n",
            "Trainign epoch is 29\n",
            "loss was 0.391888. Updating learning rate to 0.000002\n",
            "Validation at Epoch 29\n",
            "val/aupr: 0.6431715488433838\n",
            "val/auroc: 0.6567164659500122\n",
            "Trainign epoch is 30\n",
            "loss was 0.480379. Updating learning rate to 0.000100\n",
            "Validation at Epoch 30\n",
            "val/aupr: 0.6431715488433838\n",
            "val/auroc: 0.6567164659500122\n",
            "Trainign epoch is 31\n",
            "loss was 0.456527. Updating learning rate to 0.000098\n",
            "Validation AUPR 0.644385 > previous max 0.643401\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch30.pt\n",
            "Validation at Epoch 31\n",
            "val/aupr: 0.6443847417831421\n",
            "val/auroc: 0.6571040749549866\n",
            "Trainign epoch is 32\n",
            "loss was 0.474391. Updating learning rate to 0.000090\n",
            "Validation AUPR 0.645058 > previous max 0.644385\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch31.pt\n",
            "Validation at Epoch 32\n",
            "val/aupr: 0.6450583934783936\n",
            "val/auroc: 0.6584609150886536\n",
            "Trainign epoch is 33\n",
            "loss was 0.413491. Updating learning rate to 0.000079\n",
            "Validation AUPR 0.645976 > previous max 0.645058\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch32.pt\n",
            "Validation at Epoch 33\n",
            "val/aupr: 0.6459764242172241\n",
            "val/auroc: 0.6584609150886536\n",
            "Trainign epoch is 34\n",
            "loss was 0.404077. Updating learning rate to 0.000065\n",
            "Validation at Epoch 34\n",
            "val/aupr: 0.6430533528327942\n",
            "val/auroc: 0.6580733060836792\n",
            "Trainign epoch is 35\n",
            "loss was 0.434038. Updating learning rate to 0.000050\n",
            "Validation at Epoch 35\n",
            "val/aupr: 0.643579363822937\n",
            "val/auroc: 0.6588485836982727\n",
            "Trainign epoch is 36\n",
            "loss was 0.549224. Updating learning rate to 0.000035\n",
            "Validation at Epoch 36\n",
            "val/aupr: 0.643949031829834\n",
            "val/auroc: 0.6598177552223206\n",
            "Trainign epoch is 37\n",
            "loss was 0.384858. Updating learning rate to 0.000021\n",
            "Validation at Epoch 37\n",
            "val/aupr: 0.6445622444152832\n",
            "val/auroc: 0.6602054834365845\n",
            "Trainign epoch is 38\n",
            "loss was 0.434051. Updating learning rate to 0.000010\n",
            "Validation at Epoch 38\n",
            "val/aupr: 0.6449140310287476\n",
            "val/auroc: 0.660399317741394\n",
            "Trainign epoch is 39\n",
            "loss was 0.429090. Updating learning rate to 0.000002\n",
            "Validation at Epoch 39\n",
            "val/aupr: 0.64500492811203\n",
            "val/auroc: 0.6605931520462036\n",
            "Trainign epoch is 40\n",
            "loss was 0.392535. Updating learning rate to 0.000100\n",
            "Validation at Epoch 40\n",
            "val/aupr: 0.64500492811203\n",
            "val/auroc: 0.6605931520462036\n",
            "Trainign epoch is 41\n",
            "loss was 0.504907. Updating learning rate to 0.000098\n",
            "Validation at Epoch 41\n",
            "val/aupr: 0.6440615653991699\n",
            "val/auroc: 0.6611745953559875\n",
            "Trainign epoch is 42\n",
            "loss was 0.306461. Updating learning rate to 0.000090\n",
            "Validation at Epoch 42\n",
            "val/aupr: 0.6441164612770081\n",
            "val/auroc: 0.6619499921798706\n",
            "Trainign epoch is 43\n",
            "loss was 0.328589. Updating learning rate to 0.000079\n",
            "Validation at Epoch 43\n",
            "val/aupr: 0.6437991261482239\n",
            "val/auroc: 0.6615623235702515\n",
            "Trainign epoch is 44\n",
            "loss was 0.352672. Updating learning rate to 0.000065\n",
            "Validation at Epoch 44\n",
            "val/aupr: 0.6453514099121094\n",
            "val/auroc: 0.6615623235702515\n",
            "Trainign epoch is 45\n",
            "loss was 0.381715. Updating learning rate to 0.000050\n",
            "Validation at Epoch 45\n",
            "val/aupr: 0.6427862644195557\n",
            "val/auroc: 0.662337601184845\n",
            "Trainign epoch is 46\n",
            "loss was 0.427795. Updating learning rate to 0.000035\n",
            "Validation at Epoch 46\n",
            "val/aupr: 0.6430739760398865\n",
            "val/auroc: 0.6625314950942993\n",
            "Trainign epoch is 47\n",
            "loss was 0.292664. Updating learning rate to 0.000021\n",
            "Validation at Epoch 47\n",
            "val/aupr: 0.6423358917236328\n",
            "val/auroc: 0.6619500517845154\n",
            "Trainign epoch is 48\n",
            "loss was 0.498299. Updating learning rate to 0.000010\n",
            "Validation at Epoch 48\n",
            "val/aupr: 0.6408581137657166\n",
            "val/auroc: 0.6613685488700867\n",
            "Trainign epoch is 49\n",
            "loss was 0.456164. Updating learning rate to 0.000002\n",
            "Validation at Epoch 49\n",
            "val/aupr: 0.6412529349327087\n",
            "val/auroc: 0.6615623831748962\n",
            "Trainign epoch is 50\n",
            "loss was 0.354259. Updating learning rate to 0.000100\n",
            "Validation at Epoch 50\n",
            "val/aupr: 0.6412529349327087\n",
            "val/auroc: 0.6615623831748962\n",
            "Trainign epoch is 51\n",
            "loss was 0.405158. Updating learning rate to 0.000098\n",
            "Validation at Epoch 51\n",
            "val/aupr: 0.6421106457710266\n",
            "val/auroc: 0.6621438264846802\n",
            "Trainign epoch is 52\n",
            "loss was 0.338803. Updating learning rate to 0.000090\n",
            "Validation at Epoch 52\n",
            "val/aupr: 0.6448091268539429\n",
            "val/auroc: 0.6635006070137024\n",
            "Trainign epoch is 53\n",
            "loss was 0.330304. Updating learning rate to 0.000079\n",
            "Validation AUPR 0.646141 > previous max 0.645976\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch52.pt\n",
            "Validation at Epoch 53\n",
            "val/aupr: 0.6461412310600281\n",
            "val/auroc: 0.664469838142395\n",
            "Trainign epoch is 54\n",
            "loss was 0.383021. Updating learning rate to 0.000065\n",
            "Validation AUPR 0.646823 > previous max 0.646141\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch53.pt\n",
            "Validation at Epoch 54\n",
            "val/aupr: 0.6468232274055481\n",
            "val/auroc: 0.6662143468856812\n",
            "Trainign epoch is 55\n",
            "loss was 0.265486. Updating learning rate to 0.000050\n",
            "Validation AUPR 0.648136 > previous max 0.646823\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch54.pt\n",
            "Validation at Epoch 55\n",
            "val/aupr: 0.648135781288147\n",
            "val/auroc: 0.6677650809288025\n",
            "Trainign epoch is 56\n",
            "loss was 0.414370. Updating learning rate to 0.000035\n",
            "Validation AUPR 0.648525 > previous max 0.648136\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch55.pt\n",
            "Validation at Epoch 56\n",
            "val/aupr: 0.6485246419906616\n",
            "val/auroc: 0.6683465242385864\n",
            "Trainign epoch is 57\n",
            "loss was 0.311131. Updating learning rate to 0.000021\n",
            "Validation at Epoch 57\n",
            "val/aupr: 0.642881453037262\n",
            "val/auroc: 0.6673774123191833\n",
            "Trainign epoch is 58\n",
            "loss was 0.347544. Updating learning rate to 0.000010\n",
            "Validation at Epoch 58\n",
            "val/aupr: 0.6475050449371338\n",
            "val/auroc: 0.6669897437095642\n",
            "Trainign epoch is 59\n",
            "loss was 0.305606. Updating learning rate to 0.000002\n",
            "Validation at Epoch 59\n",
            "val/aupr: 0.6475891470909119\n",
            "val/auroc: 0.6673774123191833\n",
            "Trainign epoch is 60\n",
            "loss was 0.448984. Updating learning rate to 0.000100\n",
            "Validation at Epoch 60\n",
            "val/aupr: 0.6476587653160095\n",
            "val/auroc: 0.6675712466239929\n",
            "Trainign epoch is 61\n",
            "loss was 0.319991. Updating learning rate to 0.000098\n",
            "Validation at Epoch 61\n",
            "val/aupr: 0.6450644731521606\n",
            "val/auroc: 0.6683465838432312\n",
            "Trainign epoch is 62\n",
            "loss was 0.270044. Updating learning rate to 0.000090\n",
            "Validation AUPR 0.658680 > previous max 0.648525\n",
            "Saving checkpoint model to saved_models/test_run_best_model_epoch61.pt\n",
            "Validation at Epoch 62\n",
            "val/aupr: 0.6586803197860718\n",
            "val/auroc: 0.669703483581543\n",
            "Trainign epoch is 63\n",
            "loss was 0.301419. Updating learning rate to 0.000079\n",
            "Validation at Epoch 63\n",
            "val/aupr: 0.6562485694885254\n",
            "val/auroc: 0.6697034239768982\n",
            "Trainign epoch is 64\n",
            "loss was 0.212866. Updating learning rate to 0.000065\n",
            "Validation at Epoch 64\n",
            "val/aupr: 0.6560616493225098\n",
            "val/auroc: 0.6700910925865173\n",
            "Trainign epoch is 65\n",
            "loss was 0.223989. Updating learning rate to 0.000050\n",
            "Validation at Epoch 65\n",
            "val/aupr: 0.6554160118103027\n",
            "val/auroc: 0.6704787611961365\n",
            "Trainign epoch is 66\n",
            "loss was 0.341167. Updating learning rate to 0.000035\n",
            "Validation at Epoch 66\n",
            "val/aupr: 0.6552547216415405\n",
            "val/auroc: 0.670672595500946\n",
            "Trainign epoch is 67\n",
            "loss was 0.272421. Updating learning rate to 0.000021\n",
            "Validation at Epoch 67\n",
            "val/aupr: 0.6555662751197815\n",
            "val/auroc: 0.6712541580200195\n",
            "Trainign epoch is 68\n",
            "loss was 0.251003. Updating learning rate to 0.000010\n",
            "Validation at Epoch 68\n",
            "val/aupr: 0.6558588743209839\n",
            "val/auroc: 0.6714479327201843\n",
            "Trainign epoch is 69\n",
            "loss was 0.216696. Updating learning rate to 0.000002\n",
            "Validation at Epoch 69\n",
            "val/aupr: 0.6559560894966125\n",
            "val/auroc: 0.6716417670249939\n",
            "Trainign epoch is 70\n",
            "loss was 0.409774. Updating learning rate to 0.000100\n",
            "Validation at Epoch 70\n",
            "val/aupr: 0.6559560894966125\n",
            "val/auroc: 0.6716417670249939\n",
            "Trainign epoch is 71\n",
            "loss was 0.293872. Updating learning rate to 0.000098\n",
            "Validation at Epoch 71\n",
            "val/aupr: 0.6464201807975769\n",
            "val/auroc: 0.6716417670249939\n",
            "Trainign epoch is 72\n",
            "loss was 0.367396. Updating learning rate to 0.000090\n",
            "Validation at Epoch 72\n",
            "val/aupr: 0.6456189155578613\n",
            "val/auroc: 0.6720294952392578\n",
            "Trainign epoch is 73\n",
            "loss was 0.288534. Updating learning rate to 0.000079\n",
            "Validation at Epoch 73\n",
            "val/aupr: 0.6460368633270264\n",
            "val/auroc: 0.6722233295440674\n",
            "Trainign epoch is 74\n",
            "loss was 0.313673. Updating learning rate to 0.000065\n",
            "Validation at Epoch 74\n",
            "val/aupr: 0.6513231992721558\n",
            "val/auroc: 0.672029435634613\n",
            "Trainign epoch is 75\n",
            "loss was 0.327916. Updating learning rate to 0.000050\n",
            "Validation at Epoch 75\n",
            "val/aupr: 0.6499858498573303\n",
            "val/auroc: 0.6718356013298035\n",
            "Trainign epoch is 76\n",
            "loss was 0.309117. Updating learning rate to 0.000035\n",
            "Validation at Epoch 76\n",
            "val/aupr: 0.6496819853782654\n",
            "val/auroc: 0.6722233295440674\n",
            "Trainign epoch is 77\n",
            "loss was 0.353267. Updating learning rate to 0.000021\n",
            "Validation at Epoch 77\n",
            "val/aupr: 0.6458554267883301\n",
            "val/auroc: 0.6722232699394226\n",
            "Trainign epoch is 78\n",
            "loss was 0.317211. Updating learning rate to 0.000010\n",
            "Validation at Epoch 78\n",
            "val/aupr: 0.6451876759529114\n",
            "val/auroc: 0.672610878944397\n",
            "Trainign epoch is 79\n",
            "loss was 0.348031. Updating learning rate to 0.000002\n",
            "Validation at Epoch 79\n",
            "val/aupr: 0.6453233957290649\n",
            "val/auroc: 0.6728047728538513\n",
            "Trainign epoch is 80\n",
            "loss was 0.286858. Updating learning rate to 0.000100\n",
            "Validation at Epoch 80\n",
            "val/aupr: 0.6453830599784851\n",
            "val/auroc: 0.6729985475540161\n",
            "Trainign epoch is 81\n",
            "loss was 0.306901. Updating learning rate to 0.000098\n",
            "Validation at Epoch 81\n",
            "val/aupr: 0.6445138454437256\n",
            "val/auroc: 0.6714479327201843\n",
            "Trainign epoch is 82\n",
            "loss was 0.301745. Updating learning rate to 0.000090\n",
            "Validation at Epoch 82\n",
            "val/aupr: 0.6467517614364624\n",
            "val/auroc: 0.6702849268913269\n",
            "Trainign epoch is 83\n",
            "loss was 0.282927. Updating learning rate to 0.000079\n",
            "Validation at Epoch 83\n",
            "val/aupr: 0.6468961238861084\n",
            "val/auroc: 0.669703483581543\n",
            "Trainign epoch is 84\n",
            "loss was 0.373674. Updating learning rate to 0.000065\n",
            "Validation at Epoch 84\n",
            "val/aupr: 0.6464548110961914\n",
            "val/auroc: 0.6706725358963013\n",
            "Trainign epoch is 85\n",
            "loss was 0.319028. Updating learning rate to 0.000050\n",
            "Validation at Epoch 85\n",
            "val/aupr: 0.6478617787361145\n",
            "val/auroc: 0.6716418266296387\n",
            "Trainign epoch is 86\n",
            "loss was 0.311194. Updating learning rate to 0.000035\n",
            "Validation at Epoch 86\n",
            "val/aupr: 0.6517397165298462\n",
            "val/auroc: 0.6726109385490417\n",
            "Trainign epoch is 87\n",
            "loss was 0.287376. Updating learning rate to 0.000021\n",
            "Validation at Epoch 87\n",
            "val/aupr: 0.6500638127326965\n",
            "val/auroc: 0.6722233295440674\n",
            "Trainign epoch is 88\n",
            "loss was 0.235402. Updating learning rate to 0.000010\n",
            "Validation at Epoch 88\n",
            "val/aupr: 0.6461548209190369\n",
            "val/auroc: 0.6718356609344482\n",
            "Trainign epoch is 89\n",
            "loss was 0.274025. Updating learning rate to 0.000002\n",
            "Validation at Epoch 89\n",
            "val/aupr: 0.6456398963928223\n",
            "val/auroc: 0.6712540984153748\n",
            "Trainign epoch is 90\n",
            "loss was 0.291037. Updating learning rate to 0.000100\n",
            "Validation at Epoch 90\n",
            "val/aupr: 0.6456398963928223\n",
            "val/auroc: 0.6712540984153748\n",
            "Trainign epoch is 91\n",
            "loss was 0.341970. Updating learning rate to 0.000098\n",
            "Validation at Epoch 91\n",
            "val/aupr: 0.645832896232605\n",
            "val/auroc: 0.6695095896720886\n",
            "Trainign epoch is 92\n",
            "loss was 0.250821. Updating learning rate to 0.000090\n",
            "Validation at Epoch 92\n",
            "val/aupr: 0.6397132873535156\n",
            "val/auroc: 0.6693156957626343\n",
            "Trainign epoch is 93\n",
            "loss was 0.231475. Updating learning rate to 0.000079\n",
            "Validation at Epoch 93\n",
            "val/aupr: 0.6408110857009888\n",
            "val/auroc: 0.6708664298057556\n",
            "Trainign epoch is 94\n",
            "loss was 0.334192. Updating learning rate to 0.000065\n",
            "Validation at Epoch 94\n",
            "val/aupr: 0.6415247321128845\n",
            "val/auroc: 0.670672595500946\n",
            "Trainign epoch is 95\n",
            "loss was 0.338264. Updating learning rate to 0.000050\n",
            "Validation at Epoch 95\n",
            "val/aupr: 0.6398425698280334\n",
            "val/auroc: 0.6708664894104004\n",
            "Trainign epoch is 96\n",
            "loss was 0.287007. Updating learning rate to 0.000035\n",
            "Validation at Epoch 96\n",
            "val/aupr: 0.6390783190727234\n",
            "val/auroc: 0.6704787015914917\n",
            "Trainign epoch is 97\n",
            "loss was 0.301632. Updating learning rate to 0.000021\n",
            "Validation at Epoch 97\n",
            "val/aupr: 0.639694333076477\n",
            "val/auroc: 0.6706726551055908\n",
            "Trainign epoch is 98\n",
            "loss was 0.227665. Updating learning rate to 0.000010\n",
            "Validation at Epoch 98\n",
            "val/aupr: 0.6385826468467712\n",
            "val/auroc: 0.6700910329818726\n",
            "Trainign epoch is 99\n",
            "loss was 0.250061. Updating learning rate to 0.000002\n",
            "Validation at Epoch 99\n",
            "val/aupr: 0.6385826468467712\n",
            "val/auroc: 0.6700910329818726\n",
            "Trainign epoch is 100\n",
            "loss was 0.360053. Updating learning rate to 0.000100\n",
            "Validation at Epoch 100\n",
            "val/aupr: 0.6385826468467712\n",
            "val/auroc: 0.6700910329818726\n",
            "Trainign epoch is 101\n",
            "loss was 0.305095. Updating learning rate to 0.000098\n",
            "Validation at Epoch 101\n",
            "val/aupr: 0.6382393836975098\n",
            "val/auroc: 0.6698972582817078\n",
            "Trainign epoch is 102\n",
            "loss was 0.282961. Updating learning rate to 0.000090\n",
            "Validation at Epoch 102\n",
            "val/aupr: 0.6374329924583435\n",
            "val/auroc: 0.6691219806671143\n",
            "Trainign epoch is 103\n",
            "loss was 0.331311. Updating learning rate to 0.000079\n",
            "Validation at Epoch 103\n",
            "val/aupr: 0.6374374032020569\n",
            "val/auroc: 0.6695095896720886\n",
            "Trainign epoch is 104\n",
            "loss was 0.264778. Updating learning rate to 0.000065\n",
            "Validation at Epoch 104\n",
            "val/aupr: 0.6371346116065979\n",
            "val/auroc: 0.6698973178863525\n",
            "Trainign epoch is 105\n",
            "loss was 0.253854. Updating learning rate to 0.000050\n",
            "Validation at Epoch 105\n",
            "val/aupr: 0.6362863779067993\n",
            "val/auroc: 0.6695096492767334\n",
            "Trainign epoch is 106\n",
            "loss was 0.397418. Updating learning rate to 0.000035\n",
            "Validation at Epoch 106\n",
            "val/aupr: 0.6356683969497681\n",
            "val/auroc: 0.6697034239768982\n",
            "Trainign epoch is 107\n",
            "loss was 0.256674. Updating learning rate to 0.000021\n",
            "Validation at Epoch 107\n",
            "val/aupr: 0.6351516842842102\n",
            "val/auroc: 0.669703483581543\n",
            "Trainign epoch is 108\n",
            "loss was 0.187652. Updating learning rate to 0.000010\n",
            "Validation at Epoch 108\n",
            "val/aupr: 0.6357128024101257\n",
            "val/auroc: 0.6698972582817078\n",
            "Trainign epoch is 109\n",
            "loss was 0.221896. Updating learning rate to 0.000002\n",
            "Validation at Epoch 109\n",
            "val/aupr: 0.6362801194190979\n",
            "val/auroc: 0.6700910925865173\n",
            "Trainign epoch is 110\n",
            "loss was 0.312351. Updating learning rate to 0.000100\n",
            "Validation at Epoch 110\n",
            "val/aupr: 0.6353755593299866\n",
            "val/auroc: 0.6698972582817078\n",
            "Trainign epoch is 111\n",
            "loss was 0.266395. Updating learning rate to 0.000098\n",
            "Validation at Epoch 111\n",
            "val/aupr: 0.6362214088439941\n",
            "val/auroc: 0.6706725358963013\n",
            "Trainign epoch is 112\n",
            "loss was 0.208638. Updating learning rate to 0.000090\n",
            "Validation at Epoch 112\n",
            "val/aupr: 0.6364720463752747\n",
            "val/auroc: 0.6714478731155396\n",
            "Trainign epoch is 113\n",
            "loss was 0.260992. Updating learning rate to 0.000079\n",
            "Validation at Epoch 113\n",
            "val/aupr: 0.6317861080169678\n",
            "val/auroc: 0.6714479327201843\n",
            "Trainign epoch is 114\n",
            "loss was 0.240004. Updating learning rate to 0.000065\n",
            "Validation at Epoch 114\n",
            "val/aupr: 0.635783851146698\n",
            "val/auroc: 0.6718356013298035\n",
            "Trainign epoch is 115\n",
            "loss was 0.322711. Updating learning rate to 0.000050\n",
            "Validation at Epoch 115\n",
            "val/aupr: 0.6327366232872009\n",
            "val/auroc: 0.6706725358963013\n",
            "Trainign epoch is 116\n",
            "loss was 0.194055. Updating learning rate to 0.000035\n",
            "Validation at Epoch 116\n",
            "val/aupr: 0.6317062973976135\n",
            "val/auroc: 0.6708664298057556\n",
            "Trainign epoch is 117\n",
            "loss was 0.266027. Updating learning rate to 0.000021\n",
            "Validation at Epoch 117\n",
            "val/aupr: 0.6317482590675354\n",
            "val/auroc: 0.6708664298057556\n",
            "Trainign epoch is 118\n",
            "loss was 0.255903. Updating learning rate to 0.000010\n",
            "Validation at Epoch 118\n",
            "val/aupr: 0.6315323114395142\n",
            "val/auroc: 0.6704788208007812\n",
            "Trainign epoch is 119\n",
            "loss was 0.198974. Updating learning rate to 0.000002\n",
            "Validation at Epoch 119\n",
            "val/aupr: 0.631540060043335\n",
            "val/auroc: 0.6704787611961365\n",
            "Trainign epoch is 120\n",
            "loss was 0.226470. Updating learning rate to 0.000100\n",
            "Validation at Epoch 120\n",
            "val/aupr: 0.631540060043335\n",
            "val/auroc: 0.6704787611961365\n",
            "Trainign epoch is 121\n",
            "loss was 0.378586. Updating learning rate to 0.000098\n",
            "Validation at Epoch 121\n",
            "val/aupr: 0.6338195204734802\n",
            "val/auroc: 0.6714479923248291\n",
            "Trainign epoch is 122\n",
            "loss was 0.252334. Updating learning rate to 0.000090\n",
            "Validation at Epoch 122\n",
            "val/aupr: 0.6316170692443848\n",
            "val/auroc: 0.6718356013298035\n",
            "Trainign epoch is 123\n",
            "loss was 0.166242. Updating learning rate to 0.000079\n",
            "Validation at Epoch 123\n",
            "val/aupr: 0.6283218860626221\n",
            "val/auroc: 0.6710602641105652\n",
            "Trainign epoch is 124\n",
            "loss was 0.177914. Updating learning rate to 0.000065\n",
            "Validation at Epoch 124\n",
            "val/aupr: 0.6230546832084656\n",
            "val/auroc: 0.6691218614578247\n",
            "Trainign epoch is 125\n",
            "loss was 0.365414. Updating learning rate to 0.000050\n",
            "Validation at Epoch 125\n",
            "val/aupr: 0.6237585544586182\n",
            "val/auroc: 0.6698973178863525\n",
            "Trainign epoch is 126\n",
            "loss was 0.204915. Updating learning rate to 0.000035\n",
            "Validation at Epoch 126\n",
            "val/aupr: 0.624494731426239\n",
            "val/auroc: 0.6700910925865173\n",
            "Trainign epoch is 127\n",
            "loss was 0.187238. Updating learning rate to 0.000021\n",
            "Validation at Epoch 127\n",
            "val/aupr: 0.6236079335212708\n",
            "val/auroc: 0.6698972582817078\n",
            "Trainign epoch is 128\n",
            "loss was 0.238678. Updating learning rate to 0.000010\n",
            "Validation at Epoch 128\n",
            "val/aupr: 0.62288498878479\n",
            "val/auroc: 0.6693156957626343\n",
            "Trainign epoch is 129\n",
            "loss was 0.202985. Updating learning rate to 0.000002\n",
            "Validation at Epoch 129\n",
            "val/aupr: 0.62288498878479\n",
            "val/auroc: 0.6693156957626343\n",
            "Trainign epoch is 130\n",
            "loss was 0.286853. Updating learning rate to 0.000100\n",
            "Validation at Epoch 130\n",
            "val/aupr: 0.62288498878479\n",
            "val/auroc: 0.6693156957626343\n",
            "Trainign epoch is 131\n",
            "loss was 0.220835. Updating learning rate to 0.000098\n",
            "Validation at Epoch 131\n",
            "val/aupr: 0.6191977262496948\n",
            "val/auroc: 0.6698973178863525\n",
            "Trainign epoch is 132\n",
            "loss was 0.301362. Updating learning rate to 0.000090\n",
            "Validation at Epoch 132\n",
            "val/aupr: 0.6122289896011353\n",
            "val/auroc: 0.669315755367279\n",
            "Trainign epoch is 133\n",
            "loss was 0.186783. Updating learning rate to 0.000079\n",
            "Validation at Epoch 133\n",
            "val/aupr: 0.610946774482727\n",
            "val/auroc: 0.6691219210624695\n",
            "Trainign epoch is 134\n",
            "loss was 0.150307. Updating learning rate to 0.000065\n",
            "Validation at Epoch 134\n",
            "val/aupr: 0.6117575168609619\n",
            "val/auroc: 0.6702849268913269\n",
            "Trainign epoch is 135\n",
            "loss was 0.179868. Updating learning rate to 0.000050\n",
            "Validation at Epoch 135\n",
            "val/aupr: 0.6129012703895569\n",
            "val/auroc: 0.6720294952392578\n",
            "Trainign epoch is 136\n",
            "loss was 0.105087. Updating learning rate to 0.000035\n",
            "Validation at Epoch 136\n",
            "val/aupr: 0.6138724684715271\n",
            "val/auroc: 0.6731924414634705\n",
            "Trainign epoch is 137\n",
            "loss was 0.217018. Updating learning rate to 0.000021\n",
            "Validation at Epoch 137\n",
            "val/aupr: 0.6139182448387146\n",
            "val/auroc: 0.6733863353729248\n",
            "Trainign epoch is 138\n",
            "loss was 0.144665. Updating learning rate to 0.000010\n",
            "Validation at Epoch 138\n",
            "val/aupr: 0.6127176880836487\n",
            "val/auroc: 0.6728048324584961\n",
            "Trainign epoch is 139\n",
            "loss was 0.162803. Updating learning rate to 0.000002\n",
            "Validation at Epoch 139\n",
            "val/aupr: 0.61277836561203\n",
            "val/auroc: 0.6729986667633057\n",
            "Trainign epoch is 140\n",
            "loss was 0.210811. Updating learning rate to 0.000100\n",
            "Validation at Epoch 140\n",
            "val/aupr: 0.61277836561203\n",
            "val/auroc: 0.6729986667633057\n",
            "Trainign epoch is 141\n",
            "loss was 0.219013. Updating learning rate to 0.000098\n",
            "Validation at Epoch 141\n",
            "val/aupr: 0.6094236969947815\n",
            "val/auroc: 0.6728047728538513\n",
            "Trainign epoch is 142\n",
            "loss was 0.220918. Updating learning rate to 0.000090\n",
            "Validation at Epoch 142\n",
            "val/aupr: 0.6089501976966858\n",
            "val/auroc: 0.6726109981536865\n",
            "Trainign epoch is 143\n",
            "loss was 0.237682. Updating learning rate to 0.000079\n",
            "Validation at Epoch 143\n",
            "val/aupr: 0.6085444688796997\n",
            "val/auroc: 0.6724171042442322\n",
            "Trainign epoch is 144\n",
            "loss was 0.230483. Updating learning rate to 0.000065\n",
            "Validation at Epoch 144\n",
            "val/aupr: 0.6080294251441956\n",
            "val/auroc: 0.6722233295440674\n",
            "Trainign epoch is 145\n",
            "loss was 0.149968. Updating learning rate to 0.000050\n",
            "Validation at Epoch 145\n",
            "val/aupr: 0.6087758541107178\n",
            "val/auroc: 0.6729986071586609\n",
            "Trainign epoch is 146\n",
            "loss was 0.293724. Updating learning rate to 0.000035\n",
            "Validation at Epoch 146\n",
            "val/aupr: 0.6074441075325012\n",
            "val/auroc: 0.6722232103347778\n",
            "Trainign epoch is 147\n",
            "loss was 0.174019. Updating learning rate to 0.000021\n",
            "Validation at Epoch 147\n",
            "val/aupr: 0.6073736548423767\n",
            "val/auroc: 0.6724171042442322\n",
            "Trainign epoch is 148\n",
            "loss was 0.276503. Updating learning rate to 0.000010\n",
            "Validation at Epoch 148\n",
            "val/aupr: 0.6081563830375671\n",
            "val/auroc: 0.6729986667633057\n",
            "Trainign epoch is 149\n",
            "loss was 0.111559. Updating learning rate to 0.000002\n",
            "Validation at Epoch 149\n",
            "val/aupr: 0.6080583333969116\n",
            "val/auroc: 0.6728048324584961\n",
            "Trainign epoch is 150\n",
            "loss was 0.341145. Updating learning rate to 0.000100\n",
            "Validation at Epoch 150\n",
            "val/aupr: 0.6080583333969116\n",
            "val/auroc: 0.6728048324584961\n",
            "Trainign epoch is 151\n",
            "loss was 0.175927. Updating learning rate to 0.000098\n",
            "Validation at Epoch 151\n",
            "val/aupr: 0.6095880270004272\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 152\n",
            "loss was 0.122772. Updating learning rate to 0.000090\n",
            "Validation at Epoch 152\n",
            "val/aupr: 0.6108888387680054\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 153\n",
            "loss was 0.176193. Updating learning rate to 0.000079\n",
            "Validation at Epoch 153\n",
            "val/aupr: 0.6126852035522461\n",
            "val/auroc: 0.6757124066352844\n",
            "Trainign epoch is 154\n",
            "loss was 0.258757. Updating learning rate to 0.000065\n",
            "Validation at Epoch 154\n",
            "val/aupr: 0.6157989501953125\n",
            "val/auroc: 0.6768753528594971\n",
            "Trainign epoch is 155\n",
            "loss was 0.290797. Updating learning rate to 0.000050\n",
            "Validation at Epoch 155\n",
            "val/aupr: 0.6162809133529663\n",
            "val/auroc: 0.6766814589500427\n",
            "Trainign epoch is 156\n",
            "loss was 0.221179. Updating learning rate to 0.000035\n",
            "Validation at Epoch 156\n",
            "val/aupr: 0.6158928275108337\n",
            "val/auroc: 0.6766815185546875\n",
            "Trainign epoch is 157\n",
            "loss was 0.236676. Updating learning rate to 0.000021\n",
            "Validation at Epoch 157\n",
            "val/aupr: 0.6161323189735413\n",
            "val/auroc: 0.6764876246452332\n",
            "Trainign epoch is 158\n",
            "loss was 0.179301. Updating learning rate to 0.000010\n",
            "Validation at Epoch 158\n",
            "val/aupr: 0.6162726283073425\n",
            "val/auroc: 0.6764876842498779\n",
            "Trainign epoch is 159\n",
            "loss was 0.197211. Updating learning rate to 0.000002\n",
            "Validation at Epoch 159\n",
            "val/aupr: 0.6164535284042358\n",
            "val/auroc: 0.6766815185546875\n",
            "Trainign epoch is 160\n",
            "loss was 0.134514. Updating learning rate to 0.000100\n",
            "Validation at Epoch 160\n",
            "val/aupr: 0.6154890060424805\n",
            "val/auroc: 0.6764876842498779\n",
            "Trainign epoch is 161\n",
            "loss was 0.154647. Updating learning rate to 0.000098\n",
            "Validation at Epoch 161\n",
            "val/aupr: 0.6167544722557068\n",
            "val/auroc: 0.6768752932548523\n",
            "Trainign epoch is 162\n",
            "loss was 0.183646. Updating learning rate to 0.000090\n",
            "Validation at Epoch 162\n",
            "val/aupr: 0.6159120202064514\n",
            "val/auroc: 0.6768753528594971\n",
            "Trainign epoch is 163\n",
            "loss was 0.185742. Updating learning rate to 0.000079\n",
            "Validation at Epoch 163\n",
            "val/aupr: 0.6164459586143494\n",
            "val/auroc: 0.6770691871643066\n",
            "Trainign epoch is 164\n",
            "loss was 0.242756. Updating learning rate to 0.000065\n",
            "Validation at Epoch 164\n",
            "val/aupr: 0.6176525950431824\n",
            "val/auroc: 0.6772630214691162\n",
            "Trainign epoch is 165\n",
            "loss was 0.210344. Updating learning rate to 0.000050\n",
            "Validation at Epoch 165\n",
            "val/aupr: 0.6155022382736206\n",
            "val/auroc: 0.6762938499450684\n",
            "Trainign epoch is 166\n",
            "loss was 0.204164. Updating learning rate to 0.000035\n",
            "Validation at Epoch 166\n",
            "val/aupr: 0.6150867342948914\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 167\n",
            "loss was 0.081627. Updating learning rate to 0.000021\n",
            "Validation at Epoch 167\n",
            "val/aupr: 0.6151508092880249\n",
            "val/auroc: 0.6759061813354492\n",
            "Trainign epoch is 168\n",
            "loss was 0.204937. Updating learning rate to 0.000010\n",
            "Validation at Epoch 168\n",
            "val/aupr: 0.6158444881439209\n",
            "val/auroc: 0.6759061813354492\n",
            "Trainign epoch is 169\n",
            "loss was 0.232750. Updating learning rate to 0.000002\n",
            "Validation at Epoch 169\n",
            "val/aupr: 0.6155363321304321\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 170\n",
            "loss was 0.194280. Updating learning rate to 0.000100\n",
            "Validation at Epoch 170\n",
            "val/aupr: 0.6155363321304321\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 171\n",
            "loss was 0.087405. Updating learning rate to 0.000098\n",
            "Validation at Epoch 171\n",
            "val/aupr: 0.6133667826652527\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 172\n",
            "loss was 0.207433. Updating learning rate to 0.000090\n",
            "Validation at Epoch 172\n",
            "val/aupr: 0.6136563420295715\n",
            "val/auroc: 0.6749370694160461\n",
            "Trainign epoch is 173\n",
            "loss was 0.214881. Updating learning rate to 0.000079\n",
            "Validation at Epoch 173\n",
            "val/aupr: 0.6131715774536133\n",
            "val/auroc: 0.6749370694160461\n",
            "Trainign epoch is 174\n",
            "loss was 0.249627. Updating learning rate to 0.000065\n",
            "Validation at Epoch 174\n",
            "val/aupr: 0.6123096346855164\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 175\n",
            "loss was 0.193913. Updating learning rate to 0.000050\n",
            "Validation at Epoch 175\n",
            "val/aupr: 0.6125093698501587\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 176\n",
            "loss was 0.224184. Updating learning rate to 0.000035\n",
            "Validation at Epoch 176\n",
            "val/aupr: 0.6109918355941772\n",
            "val/auroc: 0.6747431755065918\n",
            "Trainign epoch is 177\n",
            "loss was 0.141298. Updating learning rate to 0.000021\n",
            "Validation at Epoch 177\n",
            "val/aupr: 0.6106785535812378\n",
            "val/auroc: 0.6747431755065918\n",
            "Trainign epoch is 178\n",
            "loss was 0.274678. Updating learning rate to 0.000010\n",
            "Validation at Epoch 178\n",
            "val/aupr: 0.6102016568183899\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 179\n",
            "loss was 0.171655. Updating learning rate to 0.000002\n",
            "Validation at Epoch 179\n",
            "val/aupr: 0.6102016568183899\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 180\n",
            "loss was 0.256846. Updating learning rate to 0.000100\n",
            "Validation at Epoch 180\n",
            "val/aupr: 0.6102016568183899\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 181\n",
            "loss was 0.196700. Updating learning rate to 0.000098\n",
            "Validation at Epoch 181\n",
            "val/aupr: 0.6127215623855591\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 182\n",
            "loss was 0.249604. Updating learning rate to 0.000090\n",
            "Validation at Epoch 182\n",
            "val/aupr: 0.6137368679046631\n",
            "val/auroc: 0.6753246188163757\n",
            "Trainign epoch is 183\n",
            "loss was 0.102363. Updating learning rate to 0.000079\n",
            "Validation at Epoch 183\n",
            "val/aupr: 0.6110031008720398\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 184\n",
            "loss was 0.210081. Updating learning rate to 0.000065\n",
            "Validation at Epoch 184\n",
            "val/aupr: 0.6103084087371826\n",
            "val/auroc: 0.6755184531211853\n",
            "Trainign epoch is 185\n",
            "loss was 0.165873. Updating learning rate to 0.000050\n",
            "Validation at Epoch 185\n",
            "val/aupr: 0.6171563267707825\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 186\n",
            "loss was 0.239662. Updating learning rate to 0.000035\n",
            "Validation at Epoch 186\n",
            "val/aupr: 0.6164008378982544\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 187\n",
            "loss was 0.159594. Updating learning rate to 0.000021\n",
            "Validation at Epoch 187\n",
            "val/aupr: 0.6164711713790894\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 188\n",
            "loss was 0.165574. Updating learning rate to 0.000010\n",
            "Validation at Epoch 188\n",
            "val/aupr: 0.6086695194244385\n",
            "val/auroc: 0.6743554472923279\n",
            "Trainign epoch is 189\n",
            "loss was 0.150096. Updating learning rate to 0.000002\n",
            "Validation at Epoch 189\n",
            "val/aupr: 0.6086196303367615\n",
            "val/auroc: 0.6743554472923279\n",
            "Trainign epoch is 190\n",
            "loss was 0.231279. Updating learning rate to 0.000100\n",
            "Validation at Epoch 190\n",
            "val/aupr: 0.6085513234138489\n",
            "val/auroc: 0.6741616129875183\n",
            "Trainign epoch is 191\n",
            "loss was 0.144983. Updating learning rate to 0.000098\n",
            "Validation at Epoch 191\n",
            "val/aupr: 0.6097396016120911\n",
            "val/auroc: 0.674743115901947\n",
            "Trainign epoch is 192\n",
            "loss was 0.160006. Updating learning rate to 0.000090\n",
            "Validation at Epoch 192\n",
            "val/aupr: 0.6109850406646729\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 193\n",
            "loss was 0.183874. Updating learning rate to 0.000079\n",
            "Validation at Epoch 193\n",
            "val/aupr: 0.611251175403595\n",
            "val/auroc: 0.6755184531211853\n",
            "Trainign epoch is 194\n",
            "loss was 0.220799. Updating learning rate to 0.000065\n",
            "Validation at Epoch 194\n",
            "val/aupr: 0.611405611038208\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 195\n",
            "loss was 0.124247. Updating learning rate to 0.000050\n",
            "Validation at Epoch 195\n",
            "val/aupr: 0.6107442378997803\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 196\n",
            "loss was 0.193198. Updating learning rate to 0.000035\n",
            "Validation at Epoch 196\n",
            "val/aupr: 0.609135627746582\n",
            "val/auroc: 0.6739678978919983\n",
            "Trainign epoch is 197\n",
            "loss was 0.205903. Updating learning rate to 0.000021\n",
            "Validation at Epoch 197\n",
            "val/aupr: 0.6095166802406311\n",
            "val/auroc: 0.6741616725921631\n",
            "Trainign epoch is 198\n",
            "loss was 0.115903. Updating learning rate to 0.000010\n",
            "Validation at Epoch 198\n",
            "val/aupr: 0.6094411015510559\n",
            "val/auroc: 0.6741616725921631\n",
            "Trainign epoch is 199\n",
            "loss was 0.206252. Updating learning rate to 0.000002\n",
            "Validation at Epoch 199\n",
            "val/aupr: 0.6098737716674805\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 200\n",
            "loss was 0.256199. Updating learning rate to 0.000100\n",
            "Validation at Epoch 200\n",
            "val/aupr: 0.6097466945648193\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 201\n",
            "loss was 0.153972. Updating learning rate to 0.000098\n",
            "Validation at Epoch 201\n",
            "val/aupr: 0.61151123046875\n",
            "val/auroc: 0.6747431755065918\n",
            "Trainign epoch is 202\n",
            "loss was 0.124664. Updating learning rate to 0.000090\n",
            "Validation at Epoch 202\n",
            "val/aupr: 0.6118788123130798\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 203\n",
            "loss was 0.082259. Updating learning rate to 0.000079\n",
            "Validation at Epoch 203\n",
            "val/aupr: 0.6096042394638062\n",
            "val/auroc: 0.6755185127258301\n",
            "Trainign epoch is 204\n",
            "loss was 0.094868. Updating learning rate to 0.000065\n",
            "Validation at Epoch 204\n",
            "val/aupr: 0.6098087430000305\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 205\n",
            "loss was 0.115672. Updating learning rate to 0.000050\n",
            "Validation at Epoch 205\n",
            "val/aupr: 0.6086556911468506\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 206\n",
            "loss was 0.106757. Updating learning rate to 0.000035\n",
            "Validation at Epoch 206\n",
            "val/aupr: 0.6064075827598572\n",
            "val/auroc: 0.6753246784210205\n",
            "Trainign epoch is 207\n",
            "loss was 0.228038. Updating learning rate to 0.000021\n",
            "Validation at Epoch 207\n",
            "val/aupr: 0.6069771647453308\n",
            "val/auroc: 0.6753246784210205\n",
            "Trainign epoch is 208\n",
            "loss was 0.078328. Updating learning rate to 0.000010\n",
            "Validation at Epoch 208\n",
            "val/aupr: 0.6067459583282471\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 209\n",
            "loss was 0.193625. Updating learning rate to 0.000002\n",
            "Validation at Epoch 209\n",
            "val/aupr: 0.6067459583282471\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 210\n",
            "loss was 0.141122. Updating learning rate to 0.000100\n",
            "Validation at Epoch 210\n",
            "val/aupr: 0.6067459583282471\n",
            "val/auroc: 0.6751308441162109\n",
            "Trainign epoch is 211\n",
            "loss was 0.167291. Updating learning rate to 0.000098\n",
            "Validation at Epoch 211\n",
            "val/aupr: 0.6111711263656616\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 212\n",
            "loss was 0.090327. Updating learning rate to 0.000090\n",
            "Validation at Epoch 212\n",
            "val/aupr: 0.6130504012107849\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 213\n",
            "loss was 0.207085. Updating learning rate to 0.000079\n",
            "Validation at Epoch 213\n",
            "val/aupr: 0.6147920489311218\n",
            "val/auroc: 0.6761000156402588\n",
            "Trainign epoch is 214\n",
            "loss was 0.179127. Updating learning rate to 0.000065\n",
            "Validation at Epoch 214\n",
            "val/aupr: 0.6123995780944824\n",
            "val/auroc: 0.6753246188163757\n",
            "Trainign epoch is 215\n",
            "loss was 0.196523. Updating learning rate to 0.000050\n",
            "Validation at Epoch 215\n",
            "val/aupr: 0.6099433898925781\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 216\n",
            "loss was 0.123485. Updating learning rate to 0.000035\n",
            "Validation at Epoch 216\n",
            "val/aupr: 0.6100956797599792\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 217\n",
            "loss was 0.190941. Updating learning rate to 0.000021\n",
            "Validation at Epoch 217\n",
            "val/aupr: 0.6089324951171875\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 218\n",
            "loss was 0.218632. Updating learning rate to 0.000010\n",
            "Validation at Epoch 218\n",
            "val/aupr: 0.6082791090011597\n",
            "val/auroc: 0.6731925010681152\n",
            "Trainign epoch is 219\n",
            "loss was 0.117926. Updating learning rate to 0.000002\n",
            "Validation at Epoch 219\n",
            "val/aupr: 0.6083487272262573\n",
            "val/auroc: 0.6733863353729248\n",
            "Trainign epoch is 220\n",
            "loss was 0.119441. Updating learning rate to 0.000100\n",
            "Validation at Epoch 220\n",
            "val/aupr: 0.6083487272262573\n",
            "val/auroc: 0.6733863353729248\n",
            "Trainign epoch is 221\n",
            "loss was 0.205844. Updating learning rate to 0.000098\n",
            "Validation at Epoch 221\n",
            "val/aupr: 0.6118553876876831\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 222\n",
            "loss was 0.104638. Updating learning rate to 0.000090\n",
            "Validation at Epoch 222\n",
            "val/aupr: 0.6041272282600403\n",
            "val/auroc: 0.6757123470306396\n",
            "Trainign epoch is 223\n",
            "loss was 0.200004. Updating learning rate to 0.000079\n",
            "Validation at Epoch 223\n",
            "val/aupr: 0.6055888533592224\n",
            "val/auroc: 0.6759061217308044\n",
            "Trainign epoch is 224\n",
            "loss was 0.077691. Updating learning rate to 0.000065\n",
            "Validation at Epoch 224\n",
            "val/aupr: 0.6044924855232239\n",
            "val/auroc: 0.6749370098114014\n",
            "Trainign epoch is 225\n",
            "loss was 0.088976. Updating learning rate to 0.000050\n",
            "Validation at Epoch 225\n",
            "val/aupr: 0.6056293845176697\n",
            "val/auroc: 0.674743115901947\n",
            "Trainign epoch is 226\n",
            "loss was 0.086891. Updating learning rate to 0.000035\n",
            "Validation at Epoch 226\n",
            "val/aupr: 0.6033861637115479\n",
            "val/auroc: 0.6733863353729248\n",
            "Trainign epoch is 227\n",
            "loss was 0.077062. Updating learning rate to 0.000021\n",
            "Validation at Epoch 227\n",
            "val/aupr: 0.6046335101127625\n",
            "val/auroc: 0.6741616725921631\n",
            "Trainign epoch is 228\n",
            "loss was 0.188064. Updating learning rate to 0.000010\n",
            "Validation at Epoch 228\n",
            "val/aupr: 0.6041600108146667\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 229\n",
            "loss was 0.138757. Updating learning rate to 0.000002\n",
            "Validation at Epoch 229\n",
            "val/aupr: 0.6049991846084595\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 230\n",
            "loss was 0.206149. Updating learning rate to 0.000100\n",
            "Validation at Epoch 230\n",
            "val/aupr: 0.6047595143318176\n",
            "val/auroc: 0.6741616725921631\n",
            "Trainign epoch is 231\n",
            "loss was 0.191274. Updating learning rate to 0.000098\n",
            "Validation at Epoch 231\n",
            "val/aupr: 0.6122110486030579\n",
            "val/auroc: 0.6739678978919983\n",
            "Trainign epoch is 232\n",
            "loss was 0.198928. Updating learning rate to 0.000090\n",
            "Validation at Epoch 232\n",
            "val/aupr: 0.6115977764129639\n",
            "val/auroc: 0.674549400806427\n",
            "Trainign epoch is 233\n",
            "loss was 0.173508. Updating learning rate to 0.000079\n",
            "Validation at Epoch 233\n",
            "val/aupr: 0.610226571559906\n",
            "val/auroc: 0.673774003982544\n",
            "Trainign epoch is 234\n",
            "loss was 0.108881. Updating learning rate to 0.000065\n",
            "Validation at Epoch 234\n",
            "val/aupr: 0.6098649501800537\n",
            "val/auroc: 0.6731925010681152\n",
            "Trainign epoch is 235\n",
            "loss was 0.211935. Updating learning rate to 0.000050\n",
            "Validation at Epoch 235\n",
            "val/aupr: 0.6102485656738281\n",
            "val/auroc: 0.6735801696777344\n",
            "Trainign epoch is 236\n",
            "loss was 0.186510. Updating learning rate to 0.000035\n",
            "Validation at Epoch 236\n",
            "val/aupr: 0.6118887662887573\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 237\n",
            "loss was 0.172976. Updating learning rate to 0.000021\n",
            "Validation at Epoch 237\n",
            "val/aupr: 0.6116565465927124\n",
            "val/auroc: 0.6743555068969727\n",
            "Trainign epoch is 238\n",
            "loss was 0.121714. Updating learning rate to 0.000010\n",
            "Validation at Epoch 238\n",
            "val/aupr: 0.6117803454399109\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 239\n",
            "loss was 0.115517. Updating learning rate to 0.000002\n",
            "Validation at Epoch 239\n",
            "val/aupr: 0.6117803454399109\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 240\n",
            "loss was 0.217600. Updating learning rate to 0.000100\n",
            "Validation at Epoch 240\n",
            "val/aupr: 0.6117803454399109\n",
            "val/auroc: 0.6745493412017822\n",
            "Trainign epoch is 241\n",
            "loss was 0.233260. Updating learning rate to 0.000098\n",
            "Validation at Epoch 241\n",
            "val/aupr: 0.6090034246444702\n",
            "val/auroc: 0.6737739443778992\n",
            "Trainign epoch is 242\n",
            "loss was 0.210212. Updating learning rate to 0.000090\n",
            "Validation at Epoch 242\n",
            "val/aupr: 0.6098228096961975\n",
            "val/auroc: 0.673774003982544\n",
            "Trainign epoch is 243\n",
            "loss was 0.120123. Updating learning rate to 0.000079\n",
            "Validation at Epoch 243\n",
            "val/aupr: 0.6095869541168213\n",
            "val/auroc: 0.6741616725921631\n",
            "Trainign epoch is 244\n",
            "loss was 0.152199. Updating learning rate to 0.000065\n",
            "Validation at Epoch 244\n",
            "val/aupr: 0.6096453666687012\n",
            "val/auroc: 0.6735801100730896\n",
            "Trainign epoch is 245\n",
            "loss was 0.154306. Updating learning rate to 0.000050\n",
            "Validation at Epoch 245\n",
            "val/aupr: 0.6113632917404175\n",
            "val/auroc: 0.6747431755065918\n",
            "Trainign epoch is 246\n",
            "loss was 0.133793. Updating learning rate to 0.000035\n",
            "Validation at Epoch 246\n",
            "val/aupr: 0.6101468801498413\n",
            "val/auroc: 0.6739678978919983\n",
            "Trainign epoch is 247\n",
            "loss was 0.155674. Updating learning rate to 0.000021\n",
            "Validation at Epoch 247\n",
            "val/aupr: 0.6104336380958557\n",
            "val/auroc: 0.6743554472923279\n",
            "Trainign epoch is 248\n",
            "loss was 0.095530. Updating learning rate to 0.000010\n",
            "Validation at Epoch 248\n",
            "val/aupr: 0.6093509197235107\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 249\n",
            "loss was 0.102181. Updating learning rate to 0.000002\n",
            "Validation at Epoch 249\n",
            "val/aupr: 0.6093509197235107\n",
            "val/auroc: 0.6739678382873535\n",
            "Trainign epoch is 250\n",
            "loss was 0.205750. Updating learning rate to 0.000100\n",
            "Validation at Epoch 250\n",
            "val/aupr: 0.6093509197235107\n",
            "val/auroc: 0.6739678382873535\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(f\"Beginning Training\")\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "for epo in range(NUM_EPOCHS): # TODO: eventually do tqdm (progress bar)\n",
        "\n",
        "    print(f\"Trainign epoch is {epo + 1}\")\n",
        "\n",
        "    # Training\n",
        "    model.train()\n",
        "    for i, batch in enumerate(training_generator):\n",
        "        # print(f\"batch number {i + 1}\")\n",
        "        pred, label = step(model, batch, DEVICE)  # batch is (2048, 1024, 1)\n",
        "        loss = loss_fct(pred, label)\n",
        "        \n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "        # break\n",
        "    lr_scheduler.step()\n",
        "    print(f\"loss was {loss.cpu().detach().numpy():8f}. Updating learning rate to {lr_scheduler.get_lr()[0]:8f}\")\n",
        "    train_losses.append(loss.cpu().detach().numpy())\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    if epo % VALIDATE_AFTER_EPOCHS == 0:\n",
        "        with torch.set_grad_enabled(False):\n",
        "            val_results = test(\n",
        "                model = model,\n",
        "                data_generator = validation_generator,\n",
        "                metrics = val_metrics,\n",
        "                device = DEVICE,\n",
        "                classify = CLASSIFY,\n",
        "            )\n",
        "            val_results[\"epoch\"] = epo \n",
        "            \n",
        "            val_losses.append(val_results[WATCH_METRIC])\n",
        "\n",
        "            if val_results[WATCH_METRIC] > max_metric:\n",
        "                print(f\"Validation AUPR {val_results[WATCH_METRIC]:8f} > previous max {max_metric:8f}\")\n",
        "                model_max = copy.deepcopy(model)\n",
        "                max_metric = val_results[WATCH_METRIC]\n",
        "                model_save_path = Path(\n",
        "                    f\"{SAVE_DIRECTORY}/{RUN_ID}_best_model_epoch{epo:02}.pt\"\n",
        "                )\n",
        "                torch.save(\n",
        "                    model_max.state_dict(),\n",
        "                    model_save_path,\n",
        "                )\n",
        "                print(f\"Saving checkpoint model to {model_save_path}\")\n",
        "                \n",
        "            print(f\"Validation at Epoch {epo + 1}\")\n",
        "            for k, v in val_results.items():\n",
        "                if not k.startswith(\"_\") and not k.startswith(\"epoch\"):\n",
        "                    print(f\"{k}: {v}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Beginning testing\n",
            "Final Testing\n",
            "test/aupr: 0.5602075457572937\n",
            "test/auroc: 0.5665671825408936\n",
            "Saving final model to saved_models/test_run_best_model.pt\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "print(\"Beginning testing\")\n",
        "try:\n",
        "    with torch.set_grad_enabled(False):\n",
        "        model_max = model_max.eval()\n",
        "\n",
        "        test_results = test(\n",
        "            model = model_max,\n",
        "            data_generator = testing_generator,\n",
        "            metrics = test_metrics,\n",
        "            device = DEVICE,\n",
        "            classify = CLASSIFY,\n",
        "        )\n",
        "        \n",
        "        test_results[\"epoch\"] = epo + 1\n",
        "\n",
        "        print(\"Final Testing\")\n",
        "        for k, v in test_results.items():\n",
        "            if not k.startswith(\"_\") and not k.startswith(\"epoch\"):\n",
        "                print(f\"{k}: {v}\")\n",
        "\n",
        "        model_save_path = Path(f\"{SAVE_DIRECTORY}/{RUN_ID}_best_model.pt\")\n",
        "        torch.save(\n",
        "            model_max.state_dict(),\n",
        "            model_save_path,\n",
        "        )\n",
        "        print(f\"Saving final model to {model_save_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Testing failed with exception {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_results(train_losses, val_losses):\n",
        "    epochs = range(1, NUM_EPOCHS + 1)\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.plot(epochs, val_losses, label='Validation aupr')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('aupr score')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Losses')\n",
        "    plt.show()\n",
        "\n",
        "plot_results(train_losses, val_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'test/aupr': tensor(0.5586), 'test/auroc': tensor(0.5618), 'epoch': 50}"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
