{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "64OJ5uNRVIy5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "from conplex_dti.featurizer import (\n",
        "    MorganFeaturizer,\n",
        "    ProtBertFeaturizer,\n",
        ")\n",
        "\n",
        "from conplex_dti.model.architectures import SimpleCoembeddingNoSigmoid\n",
        "from conplex_dti.model.architectures import SimpleCoembedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-JN51AKTueT",
        "outputId": "42d955a9-04c8-4bb1-eb6b-922cccb737e1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = \"cpu\"\n",
        "model = SimpleCoembeddingNoSigmoid(2048, 1024, 1024)  # TODO: drug_featurizer.shape, target_featurizer.shape 2048, 1024, 1024\n",
        "model.load_state_dict(torch.load(\"../pre_trained_model/models/ConPLex_v1_BindingDB.pt\", map_location=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zTCNOCLY171",
        "outputId": "30d37de0-d92d-4a4a-8562-107205b6390c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SimpleCoembedding(\n",
            "  (drug_projector): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (target_projector): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (activator): Cosine()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<generator object Module.parameters at 0x1378e0350>\n"
          ]
        }
      ],
      "source": [
        "print(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c0Y-rpxkm89",
        "outputId": "081ebc0d-2b4e-457c-c289-bd05ef51cf48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0047, -0.0079,  0.0238,  ...,  0.0111,  0.0210,  0.0207],\n",
            "        [ 0.0153,  0.0114, -0.0300,  ...,  0.0068, -0.0462, -0.0392],\n",
            "        [ 0.0016,  0.0115, -0.0180,  ..., -0.0070, -0.0049, -0.0085],\n",
            "        ...,\n",
            "        [ 0.0366, -0.0195,  0.0033,  ...,  0.0002, -0.0111, -0.0228],\n",
            "        [ 0.0404,  0.0027,  0.0098,  ..., -0.0241, -0.0017, -0.0129],\n",
            "        [-0.0063,  0.0096, -0.0328,  ...,  0.0028,  0.0066, -0.0292]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0171, -0.0019, -0.0151,  ..., -0.0408, -0.0276, -0.0064],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0145, -0.0040,  0.0165,  ...,  0.0232,  0.0239, -0.0087],\n",
            "        [ 0.0004,  0.0061, -0.0367,  ..., -0.0063, -0.0146, -0.0555],\n",
            "        [-0.0189, -0.0549,  0.0328,  ..., -0.0027, -0.0060,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0331, -0.0179, -0.0203,  ...,  0.0261, -0.0122, -0.0455],\n",
            "        [ 0.0083, -0.0030,  0.0434,  ...,  0.0112,  0.0150, -0.0119],\n",
            "        [-0.0156,  0.0300,  0.0187,  ...,  0.0637,  0.0372,  0.0134]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0167,  0.0247, -0.0026,  ..., -0.0017, -0.0298, -0.0297],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in model.parameters():\n",
        "  # print(param.data)\n",
        "  print(param)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: eventually move TransferCoembedding class to architectures.py\n",
        "class Cosine(nn.Module):\n",
        "    def forward(self, x1, x2):\n",
        "        return nn.CosineSimilarity()(x1, x2)\n",
        "\n",
        "\n",
        "DISTANCE_METRICS = {\n",
        "    \"Cosine\": Cosine,\n",
        "}\n",
        "ACTIVATIONS = {\"ReLU\": nn.ReLU }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "u0RmY82aZwyn"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "# Create a new model that has 2 layers of tensors instead of 1.\n",
        "class TransferCoembedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pre_trained_model:SimpleCoembedding,\n",
        "        drug_shape=2048,\n",
        "        target_shape=1024,\n",
        "        latent_dimension=1024,\n",
        "        latent_activation=\"ReLU\",\n",
        "        latent_distance=\"Cosine\",\n",
        "        classify=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # TODO: initialize these all baased on the pre-trained model\n",
        "        self.drug_shape = drug_shape\n",
        "        self.target_shape = target_shape\n",
        "        self.latent_dimension = latent_dimension\n",
        "        self.do_classify = classify\n",
        "        self.latent_activation = ACTIVATIONS[latent_activation]\n",
        "\n",
        "        self.drug_projector = nn.Sequential(\n",
        "            nn.Linear(self.drug_shape, latent_dimension),     # [0]\n",
        "            self.latent_activation(),                         # [1]\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),    # [2]\n",
        "            self.latent_activation()                          # [3]\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.drug_projector[0] = copy.deepcopy(pre_trained_model.drug_projector[0])\n",
        "        # initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.drug_projector[2].weight)\n",
        "\n",
        "        self.target_projector = nn.Sequential(\n",
        "            nn.Linear(self.target_shape, latent_dimension),\n",
        "            self.latent_activation(),\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),\n",
        "            self.latent_activation()\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.target_projector[0] = copy.deepcopy(pre_trained_model.target_projector[0])\n",
        "        # initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.target_projector[2].weight)\n",
        "\n",
        "        # freeze the first layers of the target and drug projectors\n",
        "        for idx, param in enumerate(self.parameters()):\n",
        "            if idx == 0 or idx == 4:\n",
        "                param.requires_grad = False\n",
        "\n",
        "\n",
        "        if self.do_classify: # if True:\n",
        "            self.distance_metric = latent_distance # \"Cosine\"\n",
        "            self.activator = DISTANCE_METRICS[self.distance_metric]() # gives it the Cosine activator function that was written\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        if self.do_classify: # if True:\n",
        "            return self.classify(drug, target)\n",
        "        else:\n",
        "            return self.regress(drug, target)\n",
        "\n",
        "    def classify(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        distance = self.activator(drug_projection, target_projection)\n",
        "        return distance.squeeze()\n",
        "\n",
        "    def regress(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        inner_prod = torch.bmm(\n",
        "            drug_projection.view(-1, 1, self.latent_dimension),\n",
        "            target_projection.view(-1, self.latent_dimension, 1),\n",
        "        ).squeeze()\n",
        "        return inner_prod.squeeze()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA0zYGV7fQAS",
        "outputId": "85c13506-9644-4e4d-e606-182d00bc8335"
      },
      "outputs": [],
      "source": [
        "new_model = TransferCoembedding(model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TransferCoembedding(\n",
            "  (drug_projector): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (target_projector): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (activator): Cosine()\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(new_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Biok7ddmC3S",
        "outputId": "48fab2f7-8686-4b9c-e8a6-944dcd5b695b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0047, -0.0079,  0.0238,  ...,  0.0111,  0.0210,  0.0207],\n",
            "        [ 0.0153,  0.0114, -0.0300,  ...,  0.0068, -0.0462, -0.0392],\n",
            "        [ 0.0016,  0.0115, -0.0180,  ..., -0.0070, -0.0049, -0.0085],\n",
            "        ...,\n",
            "        [ 0.0366, -0.0195,  0.0033,  ...,  0.0002, -0.0111, -0.0228],\n",
            "        [ 0.0404,  0.0027,  0.0098,  ..., -0.0241, -0.0017, -0.0129],\n",
            "        [-0.0063,  0.0096, -0.0328,  ...,  0.0028,  0.0066, -0.0292]])\n",
            "Parameter containing:\n",
            "tensor([-0.0171, -0.0019, -0.0151,  ..., -0.0408, -0.0276, -0.0064],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0318, -0.0216, -0.0370,  ...,  0.0173,  0.0011,  0.0305],\n",
            "        [-0.0140, -0.0610, -0.0161,  ...,  0.0248,  0.0046, -0.0195],\n",
            "        [-0.0015, -0.0444,  0.0276,  ..., -0.0216,  0.0181,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0413,  0.0315,  0.0131,  ...,  0.0262, -0.0524,  0.0279],\n",
            "        [-0.0644,  0.0080,  0.0644,  ...,  0.0082, -0.0271, -0.0255],\n",
            "        [-0.0073,  0.0205, -0.0093,  ...,  0.0099,  0.0385, -0.0277]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0166,  0.0126, -0.0016,  ...,  0.0148,  0.0041, -0.0131],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0145, -0.0040,  0.0165,  ...,  0.0232,  0.0239, -0.0087],\n",
            "        [ 0.0004,  0.0061, -0.0367,  ..., -0.0063, -0.0146, -0.0555],\n",
            "        [-0.0189, -0.0549,  0.0328,  ..., -0.0027, -0.0060,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0331, -0.0179, -0.0203,  ...,  0.0261, -0.0122, -0.0455],\n",
            "        [ 0.0083, -0.0030,  0.0434,  ...,  0.0112,  0.0150, -0.0119],\n",
            "        [-0.0156,  0.0300,  0.0187,  ...,  0.0637,  0.0372,  0.0134]])\n",
            "Parameter containing:\n",
            "tensor([-0.0167,  0.0247, -0.0026,  ..., -0.0017, -0.0298, -0.0297],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0015,  0.0161, -0.0169,  ..., -0.0334, -0.0148, -0.0024],\n",
            "        [ 0.0311,  0.0064, -0.0310,  ...,  0.0229, -0.0078,  0.0112],\n",
            "        [-0.0201, -0.0625, -0.0336,  ...,  0.0322, -0.0105, -0.0665],\n",
            "        ...,\n",
            "        [ 0.0011,  0.0014, -0.0583,  ..., -0.0307, -0.0193, -0.0158],\n",
            "        [ 0.0619,  0.0195,  0.0053,  ...,  0.0658, -0.0003,  0.0067],\n",
            "        [-0.0141, -0.0206,  0.0098,  ...,  0.0031,  0.0149,  0.0002]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0047,  0.0273,  0.0157,  ..., -0.0165,  0.0074,  0.0207],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "for param in new_model.parameters():\n",
        "    print(param)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KRQTM4GmbIXY"
      },
      "source": [
        "there are 2 ways to apply transfer learning.\n",
        "\n",
        "1. Give the model the new images and allow it to train with a lower learning rate\n",
        "2. take the given model and freeze all layers except for the last, output layer, then retrain\n",
        "\n",
        "we are going to adopt method 2., since our model has only one layer, we are adding a 2nd layer that is randomly initialized"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1uBLuSKlcibF"
      },
      "source": [
        "NOTES:\n",
        "- will get bitter data from paper and give binding vs not binding for bitter molecules and receptors so we can do binary training\n",
        "- still unsure on how we will do sweet molecules / address the sweet receptor\n",
        "- other people are also interested in this, so we could potentially contribute it back to sam\n",
        "- we could also apply method 1 as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bcthvn10mFQr"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "\n",
        "\n",
        "# - use constrative dataset as input for two models: one that is the original with a lower learning rate,\n",
        "#   the ohter model that is our creation\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create a DTIDataModule (from conplex_dti/dataset/datamodules.py)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "upLSKOGy0ZUF"
      },
      "outputs": [],
      "source": [
        "# import pytorch_lightning as pl\n",
        "# from conplex_dti.featurizer import Featurizer\n",
        "# import typing as T\n",
        "# from pathlib import Path\n",
        "\n",
        "\n",
        "# def drug_target_collate_fn(args: T.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]):\n",
        "#     \"\"\"\n",
        "#     Collate function for PyTorch data loader -- turn a batch of triplets into a triplet of batches\n",
        "\n",
        "#     If target embeddings are not all the same length, it will zero pad them\n",
        "#     This is to account for differences in length from FoldSeek embeddings\n",
        "\n",
        "#     :param args: Batch of training samples with molecule, protein, and affinity\n",
        "#     :type args: Iterable[Tuple[torch.Tensor, torch.Tensor, torch.Tensor]]\n",
        "#     :return: Create a batch of examples\n",
        "#     :rtype: T.Tuple[torch.Tensor, torch.Tensor, torch.Tensor]\n",
        "#     \"\"\"\n",
        "#     d_emb = [a[0] for a in args]\n",
        "#     t_emb = [a[1] for a in args]\n",
        "#     labs = [a[2] for a in args]\n",
        "\n",
        "#     drugs = torch.stack(d_emb, 0)\n",
        "#     targets = pad_sequence(t_emb, batch_first=True, padding_value=FOLDSEEK_MISSING_IDX)\n",
        "#     labels = torch.stack(labs, 0)\n",
        "\n",
        "#     return drugs, targets, labels\n",
        "\n",
        "\n",
        "# class DTIDataModule(pl.LightningDataModule):\n",
        "#     def __init__(\n",
        "#         self,\n",
        "#         data_dir: str,\n",
        "#         drug_featurizer: Featurizer,\n",
        "#         target_featurizer: Featurizer,\n",
        "#         device: torch.device = torch.device(\"cpu\"),\n",
        "#         batch_size: int = 32,\n",
        "#         shuffle: bool = True,\n",
        "#         num_workers: int = 0,\n",
        "#         header=0,\n",
        "#         index_col=0,\n",
        "#         sep=\",\",\n",
        "#     ):\n",
        "#         self._loader_kwargs = {\n",
        "#             \"batch_size\": batch_size,\n",
        "#             \"shuffle\": shuffle,\n",
        "#             \"num_workers\": num_workers,\n",
        "#             \"collate_fn\": drug_target_collate_fn,\n",
        "#         }\n",
        "\n",
        "#         self._csv_kwargs = {\n",
        "#             \"header\": header,\n",
        "#             \"index_col\": index_col,\n",
        "#             \"sep\": sep,\n",
        "#         }\n",
        "\n",
        "#         self._device = device\n",
        "\n",
        "#         self._data_dir = Path(data_dir)\n",
        "#         self._train_path = Path(\"train.csv\")\n",
        "#         self._val_path = Path(\"val.csv\")\n",
        "#         self._test_path = Path(\"test.csv\")\n",
        "\n",
        "#         self._drug_column = \"SMILES\"\n",
        "#         self._target_column = \"Target Sequence\"\n",
        "#         self._label_column = \"Label\"\n",
        "\n",
        "#         self.drug_featurizer = drug_featurizer\n",
        "#         self.target_featurizer = target_featurizer\n",
        "\n",
        "#     def prepare_data(self):\n",
        "#         if self.drug_featurizer.path.exists() and self.target_featurizer.path.exists():\n",
        "#             logg.warning(\"Drug and target featurizers already exist\")\n",
        "#             return\n",
        "\n",
        "#         df_train = pd.read_csv(self._data_dir / self._train_path, **self._csv_kwargs)\n",
        "\n",
        "#         df_val = pd.read_csv(self._data_dir / self._val_path, **self._csv_kwargs)\n",
        "\n",
        "#         df_test = pd.read_csv(self._data_dir / self._test_path, **self._csv_kwargs)\n",
        "\n",
        "#         dataframes = [df_train, df_val, df_test]\n",
        "\n",
        "#         all_drugs = pd.concat([i[self._drug_column] for i in dataframes]).unique()\n",
        "\n",
        "\n",
        "#         all_targets = pd.concat([i[self._target_column] for i in dataframes]).unique()\n",
        "\n",
        "#         if self._device.type == \"cuda\":\n",
        "#             self.drug_featurizer.cuda(self._device)\n",
        "#             self.target_featurizer.cuda(self._device)\n",
        "\n",
        "#         if not self.drug_featurizer.path.exists():\n",
        "#             self.drug_featurizer.write_to_disk(all_drugs)\n",
        "\n",
        "#         if not self.target_featurizer.path.exists():\n",
        "#             self.target_featurizer.write_to_disk(all_targets)\n",
        "\n",
        "#         self.drug_featurizer.cpu()\n",
        "#         self.target_featurizer.cpu()\n",
        "\n",
        "#     def setup(self, stage: T.Optional[str] = None):\n",
        "#         self.df_train = pd.read_csv(\n",
        "#             self._data_dir / self._train_path, **self._csv_kwargs\n",
        "#         )\n",
        "\n",
        "#         self.df_val = pd.read_csv(self._data_dir / self._val_path, **self._csv_kwargs)\n",
        "\n",
        "#         self.df_test = pd.read_csv(self._data_dir / self._test_path, **self._csv_kwargs)\n",
        "\n",
        "#         self._dataframes = [self.df_train, self.df_val, self.df_test]\n",
        "\n",
        "#         all_drugs = pd.concat([i[self._drug_column] for i in self._dataframes]).unique()\n",
        "#         all_targets = pd.concat(\n",
        "#             [i[self._target_column] for i in self._dataframes]\n",
        "#         ).unique()\n",
        "\n",
        "#         if self._device.type == \"cuda\":\n",
        "#             self.drug_featurizer.cuda(self._device)\n",
        "#             self.target_featurizer.cuda(self._device)\n",
        "\n",
        "#         self.drug_featurizer.preload(all_drugs)\n",
        "#         self.drug_featurizer.cpu()\n",
        "\n",
        "#         self.target_featurizer.preload(all_targets)\n",
        "#         self.target_featurizer.cpu()\n",
        "\n",
        "#         if stage == \"fit\" or stage is None:\n",
        "#             self.data_train = BinaryDataset(\n",
        "#                 self.df_train[self._drug_column],\n",
        "#                 self.df_train[self._target_column],\n",
        "#                 self.df_train[self._label_column],\n",
        "#                 self.drug_featurizer,\n",
        "#                 self.target_featurizer,\n",
        "#             )\n",
        "\n",
        "#             self.data_val = BinaryDataset(\n",
        "#                 self.df_val[self._drug_column],\n",
        "#                 self.df_val[self._target_column],\n",
        "#                 self.df_val[self._label_column],\n",
        "#                 self.drug_featurizer,\n",
        "#                 self.target_featurizer,\n",
        "#             )\n",
        "\n",
        "#         if stage == \"test\" or stage is None:\n",
        "#             self.data_test = BinaryDataset(\n",
        "#                 self.df_test[self._drug_column],\n",
        "#                 self.df_test[self._target_column],\n",
        "#                 self.df_test[self._label_column],\n",
        "#                 self.drug_featurizer,\n",
        "#                 self.target_featurizer,\n",
        "#             )\n",
        "\n",
        "#     def train_dataloader(self):\n",
        "#         return DataLoader(self.data_train, **self._loader_kwargs)\n",
        "\n",
        "#     def val_dataloader(self):\n",
        "#         return DataLoader(self.data_val, **self._loader_kwargs)\n",
        "\n",
        "#     def test_dataloader(self):\n",
        "#         return DataLoader(self.data_test, **self._loader_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "from conplex_dti.dataset.datamodules import DTIDataModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# drug_featurizer = MorganFeaturizer()\n",
        "# target_featurizer = ProtBertFeaturizer()\n",
        "# our_data = DTIDataModule(data_dir = \"./data/\", drug_featurizer=drug_featurizer, target_featurizer=target_featurizer, batch_size = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at Rostlab/prot_bert were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "drug_featurizer = MorganFeaturizer()\n",
        "target_featurizer = ProtBertFeaturizer()\n",
        "our_data = DTIDataModule(data_dir = \"./data/\", drug_featurizer=drug_featurizer, target_featurizer=target_featurizer, batch_size = 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Drug and target featurizers already exist\n",
            "Morgan: 100%|██████████| 4/4 [00:00<00:00, 2465.79it/s]\n",
            "ProtBert: 100%|██████████| 2/2 [00:00<00:00, 3036.05it/s]\n"
          ]
        }
      ],
      "source": [
        "our_data.prepare_data()\n",
        "our_data.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NotADirectoryError",
          "evalue": "[Errno 20] Not a directory: 'bitter_training_data.csv/train.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32m/Users/charlottev/Desktop/Desktop/taste/ConPLex_Transfer_Learning_v1/conplex_dti/Transfer_learning-2.ipynb Cell 20\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/charlottev/Desktop/Desktop/taste/ConPLex_Transfer_Learning_v1/conplex_dti/Transfer_learning-2.ipynb#X50sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m our_data\u001b[39m.\u001b[39;49mprepare_data()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/charlottev/Desktop/Desktop/taste/ConPLex_Transfer_Learning_v1/conplex_dti/Transfer_learning-2.ipynb#X50sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m our_data\u001b[39m.\u001b[39msetup()\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/conplex_dti/dataset/datamodules.py:228\u001b[0m, in \u001b[0;36mDTIDataModule.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     logg\u001b[39m.\u001b[39mwarning(\u001b[39m\"\u001b[39m\u001b[39mDrug and target featurizers already exist\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    226\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 228\u001b[0m df_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_dir \u001b[39m/\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_path, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_csv_kwargs)\n\u001b[1;32m    230\u001b[0m df_val \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_val_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_csv_kwargs)\n\u001b[1;32m    232\u001b[0m df_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_test_path, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_csv_kwargs)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
            "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: 'bitter_training_data.csv/train.csv'"
          ]
        }
      ],
      "source": [
        "our_data.setup()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ggf2dfej0vZN"
      },
      "source": [
        "## Train the (new) model:\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- since the sate we are working "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9Pg3cj10xUg"
      },
      "outputs": [],
      "source": [
        "# sam's function for gettina prediction and label\n",
        "\n",
        "def step(model, batch, device=None):\n",
        "    # if device is None:\n",
        "    #     device = torch.device(\"cpu\")\n",
        "\n",
        "    drug, target, label = batch  # target is (D + N_pool)\n",
        "    pred = model(drug.to(device), target.to(device))\n",
        "    label = Variable(torch.from_numpy(np.array(label)).float()).to(device)\n",
        "    return pred, label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# test the step function:\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
