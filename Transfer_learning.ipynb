{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrlatte/TransferLearning/blob/main/Transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K7EWGhVSzjo"
      },
      "outputs": [],
      "source": [
        "!pip install conplex-dti\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conplex-dti download --to . --models ConPLex_v1_BindingDB"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kGvv6yiTovp",
        "outputId": "a307ed8d-75e4-4d66-a3a0-842274d18b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-12 13:38:59,158 [INFO] Download Location: /content\n",
            "2023-07-12 13:38:59,158 [INFO] \n",
            "2023-07-12 13:38:59,158 [INFO] [BENCHMARKS]\n",
            "2023-07-12 13:38:59,158 [INFO] [MODELS]\n",
            "2023-07-12 13:38:59,158 [INFO] Downloading ConPLex_v1_BindingDB from https://cb.csail.mit.edu/cb/conplex/data/models/BindingDB_ExperimentalValidModel.pt to /content/models/ConPLex_v1_BindingDB.pt...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "class Cosine(nn.Module):\n",
        "    def forward(self, x1, x2):\n",
        "        return nn.CosineSimilarity()(x1, x2)\n",
        "\n",
        "\n",
        "DISTANCE_METRICS = {\n",
        "    \"Cosine\": Cosine\n",
        "}\n",
        "\n",
        "ACTIVATIONS = {\"ReLU\": nn.ReLU, \"GELU\": nn.GELU, \"ELU\": nn.ELU, \"Sigmoid\": nn.Sigmoid}\n",
        "\n",
        "\n",
        "class SimpleCoembedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        drug_shape=2048,\n",
        "        target_shape=1024,\n",
        "        latent_dimension=1024,\n",
        "        latent_activation=\"ReLU\",\n",
        "        latent_distance=\"Cosine\",\n",
        "        classify=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.drug_shape = drug_shape\n",
        "        self.target_shape = target_shape\n",
        "        self.latent_dimension = latent_dimension\n",
        "        self.do_classify = classify\n",
        "        self.latent_activation = ACTIVATIONS[latent_activation]\n",
        "\n",
        "        self.drug_projector = nn.Sequential(\n",
        "            nn.Linear(self.drug_shape, latent_dimension),\n",
        "            self.latent_activation()\n",
        "        )\n",
        "        nn.init.xavier_normal_(self.drug_projector[0].weight)\n",
        "\n",
        "        self.target_projector = nn.Sequential(\n",
        "            nn.Linear(self.target_shape, latent_dimension), self.latent_activation()\n",
        "        )\n",
        "        nn.init.xavier_normal_(self.target_projector[0].weight)\n",
        "\n",
        "        if self.do_classify:\n",
        "            self.distance_metric = latent_distance\n",
        "            self.activator = DISTANCE_METRICS[self.distance_metric]()\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        if self.do_classify:\n",
        "            return self.classify(drug, target)\n",
        "        else:\n",
        "            return self.regress(drug, target)\n",
        "\n",
        "    def regress(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        inner_prod = torch.bmm(\n",
        "            drug_projection.view(-1, 1, self.latent_dimension),\n",
        "            target_projection.view(-1, self.latent_dimension, 1),\n",
        "        ).squeeze()\n",
        "        return inner_prod.squeeze()\n",
        "\n",
        "    def classify(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        distance = self.activator(drug_projection, target_projection)\n",
        "        return distance.squeeze()\n",
        "\n",
        "\n",
        "SimpleCoembeddingNoSigmoid = SimpleCoembedding"
      ],
      "metadata": {
        "id": "64OJ5uNRVIy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rTgfRPRmYK1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleCoembeddingNoSigmoid(2048, 1024, 1024)\n",
        "model.load_state_dict(torch.load(\"/content/models/ConPLex_v1_BindingDB.pt\", map_location=\"cpu\"))\n",
        "# model = model.eval()\n",
        "# model = model.to(device)\n"
      ],
      "metadata": {
        "id": "Z-JN51AKTueT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1de3384-8abb-4bd0-a92b-e58025f8276f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zTCNOCLY171",
        "outputId": "1a1dce10-b8c8-494f-984d-89073292ec1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCoembedding(\n",
            "  (drug_projector): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (target_projector): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (activator): Cosine()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  # print(param.data)\n",
        "  print(param)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c0Y-rpxkm89",
        "outputId": "595db2a5-dcf7-4f4e-9b86-a77941f45484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0047, -0.0079,  0.0238,  ...,  0.0111,  0.0210,  0.0207],\n",
            "        [ 0.0153,  0.0114, -0.0300,  ...,  0.0068, -0.0462, -0.0392],\n",
            "        [ 0.0016,  0.0115, -0.0180,  ..., -0.0070, -0.0049, -0.0085],\n",
            "        ...,\n",
            "        [ 0.0366, -0.0195,  0.0033,  ...,  0.0002, -0.0111, -0.0228],\n",
            "        [ 0.0404,  0.0027,  0.0098,  ..., -0.0241, -0.0017, -0.0129],\n",
            "        [-0.0063,  0.0096, -0.0328,  ...,  0.0028,  0.0066, -0.0292]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0171, -0.0019, -0.0151,  ..., -0.0408, -0.0276, -0.0064],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0145, -0.0040,  0.0165,  ...,  0.0232,  0.0239, -0.0087],\n",
            "        [ 0.0004,  0.0061, -0.0367,  ..., -0.0063, -0.0146, -0.0555],\n",
            "        [-0.0189, -0.0549,  0.0328,  ..., -0.0027, -0.0060,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0331, -0.0179, -0.0203,  ...,  0.0261, -0.0122, -0.0455],\n",
            "        [ 0.0083, -0.0030,  0.0434,  ...,  0.0112,  0.0150, -0.0119],\n",
            "        [-0.0156,  0.0300,  0.0187,  ...,  0.0637,  0.0372,  0.0134]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0167,  0.0247, -0.0026,  ..., -0.0017, -0.0298, -0.0297],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TransferCoembedding(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        pre_trained_model:SimpleCoembedding,\n",
        "        drug_shape=2048,\n",
        "        target_shape=1024,\n",
        "        latent_dimension=1024,\n",
        "        latent_activation=\"ReLU\",\n",
        "        latent_distance=\"Cosine\",\n",
        "        classify=True,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # TODO: initialize these all baased on the pre-trained model\n",
        "        self.drug_shape = drug_shape\n",
        "        self.target_shape = target_shape\n",
        "        self.latent_dimension = latent_dimension\n",
        "        self.do_classify = classify\n",
        "        self.latent_activation = ACTIVATIONS[latent_activation]\n",
        "\n",
        "        self.drug_projector = nn.Sequential(\n",
        "            nn.Linear(self.drug_shape, latent_dimension),     # [0]\n",
        "            self.latent_activation(),                         # [1]\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),    # [2]\n",
        "            self.latent_activation()                          # [3]\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.drug_projector[0] = pre_trained_model.drug_projector[0]\n",
        "        # TODO: freeze layer 0\n",
        "        self.drug_projector[0].requires_grad = False\n",
        "\n",
        "        # TODO: initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.drug_projector[2].weight)\n",
        "\n",
        "        self.target_projector = nn.Sequential(\n",
        "            nn.Linear(self.target_shape, latent_dimension),\n",
        "            self.latent_activation(),\n",
        "            # ADD AN ADDITIONAL LAYER AND ACTIVATION FUNCTION\n",
        "            nn.Linear(latent_dimension, latent_dimension),\n",
        "            self.latent_activation()\n",
        "        )\n",
        "\n",
        "        # initialize layer 0 from pre-trained model:\n",
        "        self.target_projector[0] = pre_trained_model.target_projector[0]\n",
        "        # TODO: freeze layer 0\n",
        "        self.target_projector[0].requires_grad = False\n",
        "        # TODO: initialize layer 2 randomly\n",
        "        nn.init.xavier_normal_(self.target_projector[2].weight)\n",
        "\n",
        "        if self.do_classify: # if True:\n",
        "            self.distance_metric = latent_distance # \"Cosine\"\n",
        "            self.activator = DISTANCE_METRICS[self.distance_metric]() # gives it the Cosine activator function that was written\n",
        "\n",
        "    def forward(self, drug, target):\n",
        "        if self.do_classify: # if True:\n",
        "            return self.classify(drug, target)\n",
        "        else:\n",
        "            return self.regress(drug, target)\n",
        "\n",
        "    def classify(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        distance = self.activator(drug_projection, target_projection)\n",
        "        return distance.squeeze()\n",
        "\n",
        "    def regress(self, drug, target):\n",
        "        drug_projection = self.drug_projector(drug)\n",
        "        target_projection = self.target_projector(target)\n",
        "\n",
        "        inner_prod = torch.bmm(\n",
        "            drug_projection.view(-1, 1, self.latent_dimension),\n",
        "            target_projection.view(-1, self.latent_dimension, 1),\n",
        "        ).squeeze()\n",
        "        return inner_prod.squeeze()\n"
      ],
      "metadata": {
        "id": "u0RmY82aZwyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = TransferCoembedding(model)\n",
        "print(new_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA0zYGV7fQAS",
        "outputId": "1b81c810-0aa2-4389-dabb-b2d5521ce058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransferCoembedding(\n",
            "  (drug_projector): Sequential(\n",
            "    (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (target_projector): Sequential(\n",
            "    (0): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "    (3): ReLU()\n",
            "  )\n",
            "  (activator): Cosine()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in new_model.parameters():\n",
        "  print(param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Biok7ddmC3S",
        "outputId": "219f4f49-3152-40c9-89cc-13e585a93443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0047, -0.0079,  0.0238,  ...,  0.0111,  0.0210,  0.0207],\n",
            "        [ 0.0153,  0.0114, -0.0300,  ...,  0.0068, -0.0462, -0.0392],\n",
            "        [ 0.0016,  0.0115, -0.0180,  ..., -0.0070, -0.0049, -0.0085],\n",
            "        ...,\n",
            "        [ 0.0366, -0.0195,  0.0033,  ...,  0.0002, -0.0111, -0.0228],\n",
            "        [ 0.0404,  0.0027,  0.0098,  ..., -0.0241, -0.0017, -0.0129],\n",
            "        [-0.0063,  0.0096, -0.0328,  ...,  0.0028,  0.0066, -0.0292]])\n",
            "Parameter containing:\n",
            "tensor([-0.0171, -0.0019, -0.0151,  ..., -0.0408, -0.0276, -0.0064])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0059,  0.0216, -0.0063,  ...,  0.0296, -0.0172,  0.0210],\n",
            "        [ 0.0604,  0.0188,  0.0035,  ...,  0.0151, -0.0138, -0.0070],\n",
            "        [-0.0070,  0.0336,  0.0219,  ...,  0.0250,  0.0536, -0.0202],\n",
            "        ...,\n",
            "        [ 0.0482, -0.0056,  0.0183,  ...,  0.0621, -0.0617, -0.0180],\n",
            "        [-0.0243, -0.0202,  0.0776,  ...,  0.0086,  0.0609, -0.0489],\n",
            "        [ 0.0073, -0.0032, -0.0295,  ...,  0.0618,  0.0370,  0.0129]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0251, -0.0240,  0.0270,  ..., -0.0257,  0.0067,  0.0026],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0145, -0.0040,  0.0165,  ...,  0.0232,  0.0239, -0.0087],\n",
            "        [ 0.0004,  0.0061, -0.0367,  ..., -0.0063, -0.0146, -0.0555],\n",
            "        [-0.0189, -0.0549,  0.0328,  ..., -0.0027, -0.0060,  0.0128],\n",
            "        ...,\n",
            "        [ 0.0331, -0.0179, -0.0203,  ...,  0.0261, -0.0122, -0.0455],\n",
            "        [ 0.0083, -0.0030,  0.0434,  ...,  0.0112,  0.0150, -0.0119],\n",
            "        [-0.0156,  0.0300,  0.0187,  ...,  0.0637,  0.0372,  0.0134]])\n",
            "Parameter containing:\n",
            "tensor([-0.0167,  0.0247, -0.0026,  ..., -0.0017, -0.0298, -0.0297])\n",
            "Parameter containing:\n",
            "tensor([[ 0.0164,  0.0049, -0.0557,  ..., -0.0216, -0.0406, -0.0176],\n",
            "        [-0.0427,  0.0038, -0.0035,  ...,  0.0141,  0.0289,  0.0217],\n",
            "        [-0.0082,  0.0052, -0.0356,  ..., -0.0082, -0.0051, -0.0055],\n",
            "        ...,\n",
            "        [-0.0409, -0.0310,  0.0024,  ..., -0.0595,  0.0380, -0.0098],\n",
            "        [ 0.0203,  0.0100,  0.0329,  ..., -0.0419,  0.0401,  0.0148],\n",
            "        [-0.0507, -0.0105,  0.0460,  ...,  0.0303, -0.0373, -0.0196]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0050,  0.0181,  0.0139,  ..., -0.0247,  0.0005, -0.0167],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bcthvn10mFQr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}